[LOG] Output is being logged to: /workspace/DFUMultiClassification/results/logs/training_fold1.log
[LOG] Started at: 2026-02-13 18:05:22


================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 2 GPU(s):
  GPU 0: NVIDIA RTX A5000 - 24.0GB (compute 8.6)
  GPU 1: NVIDIA RTX A5000 - 24.0GB (compute 8.6)

Selected 2 GPU(s):
  GPU 0: NVIDIA RTX A5000 (24.0GB)
  GPU 1: NVIDIA RTX A5000 (24.0GB)
Enabled memory growth for 2 GPU(s)

Using MirroredStrategy (2 GPUs) with NCCL
  Compute capability 8.6 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 2Ã— global batch size
================================================================================


Batch size per replica: 300 (global batch size: 600, replicas: 2)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 40.0%
Verbosity: 2 (DETAILED)
Device: GPUs [0, 1] (multi-GPU mode, MirroredStrategy)
  Replicas: 2Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 256x256
Batch size: 600
  Per-GPU batch: 300 (600 / 2 GPUs)
Max epochs: 200 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Models: 6 files deleted
  Predictions: 24 files deleted
  Csv Results: 11 files deleted
  Tf Cache: 6 files deleted
================================================================================


Data Cleaning Configuration (from production_config.py):
  Outlier removal: False
  Misclassification tracking: none
Outlier removal disabled
Confidence filtering skipped (running specific fold subprocess)

================================================================================
MODALITY SEARCH MODE: CUSTOM (1 combinations)
================================================================================
Testing only specified combinations from production_config.py
Total combinations to test: 1
Cross-validation mode: 2-fold CV
Iterations per combination: 2
Total training sessions: 2
Results will be saved to: /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv
================================================================================


Testing modalities: metadata, depth_rgb
DEBUG CONF-FILTER: CONFIDENCE_EXCLUSION_FILE env = /workspace/DFUMultiClassification/results/confidence_exclusion_list.txt
DEBUG CONF-FILTER: File exists = True
DEBUG CONF-FILTER: Loaded 109 excluded IDs from file
DEBUG CONF-FILTER: Sample IDs in data (first 3): ['P092A01D1', 'P092A01D1', 'P005A04D1']
DEBUG CONF-FILTER: Sample IDs in exclusion (first 3): ['P077A00D1', 'P090A03D1', 'P067A03D1']
DEBUG CONF-FILTER: Matched & excluded 526 samples
Confidence filtering: excluded 526/3108 samples (16.9%)
Number of samples for each selected modality:
  depth_rgb: 2582
  depth_bb: 2582
  metadata: 2582
Using 40.0% of the data: 1033 samples
Using strategy from main: MirroredStrategy

================================================================================
MULTI-GPU TRAINING: 2 GPUs
Global batch size: 600 (per-GPU: 300)
Strategy: MirroredStrategy
================================================================================


================================================================================
GENERATING 2-FOLD CROSS-VALIDATION SPLITS (PATIENT-LEVEL)
================================================================================

================================================================================
STRATIFIED K-FOLD SPLIT - CLASS DISTRIBUTION CHECK
================================================================================
Class 0: 72 patients
Class 1: 98 patients
Class 2: 32 patients
================================================================================

Fold 1/2: 101 train patients, 101 valid patients
  Train dist: {0: 0.312, 1: 0.599, 2: 0.089}
  Valid dist: {0: 0.299, 1: 0.552, 2: 0.149}
Fold 2/2: 101 train patients, 101 valid patients
  Train dist: {0: 0.299, 1: 0.552, 2: 0.149}
  Valid dist: {0: 0.312, 1: 0.599, 2: 0.089}
Generated 2 folds
All data will be validated exactly once across all folds
================================================================================


Fold 1/2
Using pre-computed fold 1 patient split
Processing metadata shape...

Unique cases: 383 (before oversampling)

True binary label distributions (unique cases):
Binary1: label_bin1
1    268
0    115
Name: count, dtype: int64
Binary2: label_bin2
0    328
1     55
Name: count, dtype: int64
Original class distribution (ordered):
Class 0: 239
Class 1: 478
Class 2: 107

Calculated alpha values from original distribution:
Alpha values (ordered) [I, P, R]: [0.804, 0.402, 1.795]
Original class distribution (ordered):
Class 0: 239
Class 1: 478
Class 2: 107
Using combined sampling (under + over)...

After undersampling (ordered):
Class 0: 239
Class 1: 239
Class 2: 107

After oversampling (ordered):
Class 0: 239
Class 1: 239
Class 2: 239

Using frequency-based weights from ORIGINAL distribution:
Alpha values [I, P, R]: [0.804, 0.402, 1.795]
(These weights emphasize minority classes even after resampling)
Feature selection: 54 â†’ 40 features
Top 5 features: ['BMI', 'Peri-Ulcer Temperature Normalized (Â°C)', 'Onset (Days)', 'Wound Centre Temperature Normalized (Â°C)', 'Intact Skin Temperature (Â°C)']
Using Scikit-learn RandomForestClassifier
Using 40 features from training selection
Healing Phase Abs type: <class 'numpy.ndarray'> shape: (717,)
Healing Phase Abs type: <class 'numpy.ndarray'> shape: (209,)
  Validation batch size adjusted: 1 â†’ 2 (n_samples=209, num_gpus=2)
Setting image shapes to 256x256...
Removed cache file: /workspace/DFUMultiClassification/results/tf_records/tf_cache_train_metadata_fold0_seed42.data-00000-of-00001
Removed cache file: /workspace/DFUMultiClassification/results/tf_records/tf_cache_train_metadata_fold0_seed42.index
Generative augmentation disabled

Preparing datasets for Fold 1/2 with all modalities: ['depth_rgb', 'metadata']
Using consistent patient split across all modality combinations for run 1

Class distributions:
Training: {0: 0.312, 1: 0.599, 2: 0.089}
Validation: {0: 0.299, 1: 0.552, 2: 0.149}

Unique cases: 232 (before oversampling)

True binary label distributions (unique cases):
Binary1: label_bin1
1    156
0     76
Name: count, dtype: int64
Binary2: label_bin2
0    206
1     26
Name: count, dtype: int64
Original class distribution (ordered):
Class 0: 157
Class 1: 302
Class 2: 45

Calculated alpha values from original distribution:
Alpha values (ordered) [I, P, R]: [0.599, 0.311, 2.09]
Original class distribution (ordered):
Class 0: 157
Class 1: 302
Class 2: 45
Using combined sampling (under + over)...

After undersampling (ordered):
Class 0: 157
Class 1: 157
Class 2: 45

After oversampling (ordered):
Class 0: 157
Class 1: 157
Class 2: 157

Using frequency-based weights from ORIGINAL distribution:
Alpha values [I, P, R]: [0.599, 0.311, 2.09]
(These weights emphasize minority classes even after resampling)
Feature selection: 54 â†’ 40 features
Top 5 features: ['Onset (Days)', 'BMI', 'Peri-Ulcer Temperature Normalized (Â°C)', 'Wound Centre Temperature Normalized (Â°C)', 'Weight (Kg)']
Using Scikit-learn RandomForestClassifier
Using 40 features from training selection
depth_rgb type: <class 'pandas.arrays.StringArray'> shape: (471,)
Healing Phase Abs type: <class 'numpy.ndarray'> shape: (471,)
Healing Phase Abs type: <class 'numpy.ndarray'> shape: (529,)
depth_rgb type: <class 'pandas.arrays.StringArray'> shape: (529,)
  Validation batch size adjusted: 600 â†’ 528 (n_samples=529, num_gpus=2)

No existing data found for metadata+depth_rgb, starting fresh

Training metadata+depth_rgb with modalities: ['metadata', 'depth_rgb'], fold 1/2
Alpha values (ordered) [I, P, R]: [0.599, 0.311, 2.09]
Class weights: {0: 1, 1: 1, 2: 1} or [1, 1, 1]

Creating image branch for depth_rgb
depth_rgb using backbone: EfficientNetB3
Loading EfficientNetB3 from ImageNet
depth_rgb using EfficientNetB3: 338 trainable weights
Model: Metadata + 1 image - two-stage fine-tuning with pre-trained image
  Fusion weights: RF=0.70, Image=0.30
  Fusion model with 1 image modalities: ['depth_rgb']
  âœ— Missing pre-trained weights for: ['depth_rgb']
    These modalities will be trained from scratch
================================================================================
AUTOMATIC PRE-TRAINING: 1 modality(ies) need training
  Missing modalities: ['depth_rgb']
  Will train each modality separately (same data split)...
================================================================================
================================================================================
PRE-TRAINING 1/1: depth_rgb
================================================================================

Creating image branch for depth_rgb
depth_rgb using backbone: EfficientNetB3
depth_rgb using EfficientNetB3: 338 trainable weights
  Pre-training depth_rgb-only on same data split (prevents data leakage)
/venv/multimodal/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
Epoch 1/200 - 32.4s - loss: 2.0934 - val_loss: 1.9443 - acc: 0.3333 - val_acc: 0.1496 - macro_f1: 0.3324 - val_macro_f1: 0.0868 - kappa: 0.0001 - val_kappa: 0.0000
Epoch 20/200 - 2.6s - loss: 2.0106 - val_loss: 1.8753 - acc: 0.4400 - val_acc: 0.1496 - macro_f1: 0.4371 - val_macro_f1: 0.0868 - kappa: 0.1593 - val_kappa: 0.0000
Epoch 21: early stopping
Restoring model weights from the end of the best epoch: 1.
  depth_rgb pre-training completed! Best val kappa: 0.0000
  Checkpoint saved to: /workspace/DFUMultiClassification/results/models/depth_rgb_1_depth_rgb.weights.h5
  Transferring depth_rgb pre-trained weights to fusion model...
  Successfully transferred 13 layers for depth_rgb!
  Saved depth_rgb pre-trained weights to cache
================================================================================
FREEZING ALL IMAGE BRANCHES FOR STAGE 1
  Pre-trained modalities to freeze: ['depth_rgb']
================================================================================
  Successfully frozen 13 layers across 1 modalities!
  Two-stage training: Stage 1 (frozen, 20 epochs) â†’ Stage 2 (fine-tune, LR=1e-6)
  DEBUG: Trainable weights breakdown after freezing:
    image_classifier: 2 trainable weights
  Total trainable parameters across all layers: 2
  DEBUG: Checking RF metadata predictions...
    Sample RF predictions (first 5): [[0.8325327  0.09877404 0.06869324]
 [0.02417901 0.01891368 0.95690733]
 [0.13776547 0.06951625 0.7927183 ]
 [0.57822955 0.10537913 0.3163913 ]
 [0.4989859  0.4188517  0.0821624 ]]
    RF predictions sum to 1.0: [0.99999994, 1.0, 1.0]
    Sample labels (first 5): [[1. 0. 0.]
 [0. 0. 1.]
 [0. 0. 1.]
 [1. 0. 0.]
 [0. 1. 0.]]
================================================================================
No existing pretrained weights found
Total model trainable weights: 2
================================================================================
STAGE 1: Training with FROZEN image branch (20 epochs)
  Goal: Stabilize fusion layer before fine-tuning image
================================================================================
Epoch 11: early stopping
Restoring model weights from the end of the best epoch: 1.
  Stage 1 completed. Best val kappa: 0.0991
================================================================================
STAGE 2: Fine-tuning with UNFROZEN image branches (1 modalities)
  Image modalities to unfreeze: ['depth_rgb']
  Learning rate: 1e-6 (very low to prevent overfitting)
  Unfreezing image layers...
================================================================================
  Successfully unfrozen 14 layers across 1 modalities
  Model recompiled with LR=1e-6
Epoch 11: early stopping
Restoring model weights from the end of the best epoch: 1.
================================================================================
Two-stage training completed!
  Stage 1 (frozen):    Kappa 0.0991
  Stage 2 (fine-tune): Kappa 0.0991
  No improvement from fine-tuning (kept Stage 1 weights)
================================================================================

Run 1 Results for metadata+depth_rgb:
Cohen's Kappa: 0.2005

Confusion Matrix (validation):
        Predicted: I    P    R
Actual Inflam:  104   43   11
Actual Prolif:  165   95   31
Actual Remodl:   29   26   24

Training gating network for run 1...

Number of models: 1

Initializing gating network training...
Number of models: 1
Shape of first model predictions: (471, 3)
Shape of true labels: (471,)
Skipping gating network: only 1 model(s), need at least 2 to combine

Gating Network Results for Run 1:
Accuracy: 0.4223
F1 Macro: 0.4016
Kappa: 0.2005
Removed cache file: /workspace/DFUMultiClassification/results/tf_records/tf_cache_train_depth_rgb_metadata_fold0_seed42.data-00000-of-00001
Removed cache file: /workspace/DFUMultiClassification/results/tf_records/tf_cache_train_depth_rgb_metadata_fold0_seed42.index
Removed cache file: /workspace/DFUMultiClassification/results/tf_records/tf_cache_valid_depth_rgb_metadata_fold0_seed42.data-00000-of-00001
Removed cache file: /workspace/DFUMultiClassification/results/tf_records/tf_cache_valid_depth_rgb_metadata_fold0_seed42.index

Fold 2/2
Using pre-computed fold 2 patient split

Fold 2/2 skipped (target_fold=1). Loading saved results...
  Warning: No saved metrics found for Fold 2/2
Results saved to /workspace/DFUMultiClassification/results/csv/modality_results_averaged.csv
Saved metadata+depth_rgb predictions to /workspace/DFUMultiClassification/results/checkpoints/combo_pred_metadata_depth_rgb_run1_train.npy
Saved metadata+depth_rgb predictions to /workspace/DFUMultiClassification/results/checkpoints/combo_pred_metadata_depth_rgb_run1_valid.npy
Results for metadata, depth_rgb appended to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb
  Accuracy: 0.4223 Â± 0.0000
  F1 Macro: 0.4016
  Kappa: 0.2005

Total combinations tested: 1
================================================================================

