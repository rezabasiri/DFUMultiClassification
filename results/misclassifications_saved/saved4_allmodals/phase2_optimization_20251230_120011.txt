================================================================================
PHASE 2 OPTIMIZATION LOG
Started: 20251230_120011
Modalities: metadata+depth_rgb+depth_map+thermal_map
Total evaluations planned: 30
CV folds per evaluation: 2
================================================================================


================================================================================
EVALUATION EVAL_1
Timestamp: 2025-12-30 12:00:11
Thresholds: I=84, P=90, R=95
================================================================================

2025-12-30 12:00:11.937883: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 12:00:11.937946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 12:00:11.939506: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 12:00:12.822338: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 1 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 84, 'P': 90, 'R': 95}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=84, P=90, R=95

Excluded samples per class:
  Class I: 123 samples
  Class P: 0 samples
  Class R: 0 samples

Total unique samples to exclude: 123

Dataset size (rows): 3107 -> 2479 (79.8%)
Unique samples: 647 -> 524 (removed 123)

Class distribution after filtering:
  Class I: 264 rows
  Class P: 1880 rows
  Class R: 335 rows
============================================================

2025-12-30 12:00:31.630950: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 12:05:05.362095: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767096404.661422  872200 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 12:09:56.114079: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.04      0.02      0.03       162
           P       0.76      0.94      0.84      1100
           R       0.00      0.00      0.00       162

    accuracy                           0.73      1424
   macro avg       0.27      0.32      0.29      1424
weighted avg       0.59      0.73      0.65      1424

Cohen's Kappa: 0.0152
2025-12-30 12:13:30.835766: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 12:19:37.462723: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 12:23:49.995454: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 8.
Epoch 28: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       102
           P       0.77      0.82      0.79       780
           R       0.28      0.35      0.31       173

    accuracy                           0.66      1055
   macro avg       0.35      0.39      0.37      1055
weighted avg       0.61      0.66      0.64      1055

Cohen's Kappa: 0.1169

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.6953 Â± 0.0308
  F1 Macro: 0.3283
  Kappa: 0.0660

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_2
Timestamp: 2025-12-30 12:29:43
Thresholds: I=89, P=83, R=86
================================================================================

2025-12-30 12:29:44.249835: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 12:29:44.249904: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 12:29:44.251380: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 12:29:45.106192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 89, 'P': 83, 'R': 86}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=89, P=83, R=86

Excluded samples per class:
  Class I: 74 samples
  Class P: 26 samples
  Class R: 14 samples

Total unique samples to exclude: 114

Dataset size (rows): 3107 -> 2449 (78.8%)
Unique samples: 647 -> 533 (removed 114)

Class distribution after filtering:
  Class I: 486 rows
  Class P: 1706 rows
  Class R: 257 rows
============================================================

2025-12-30 12:30:03.256770: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 12:34:31.796983: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767098175.130960 1016653 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 12:39:08.582181: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.15      0.02      0.03       236
           P       0.73      0.98      0.84       962
           R       0.00      0.00      0.00       110

    accuracy                           0.72      1308
   macro avg       0.30      0.33      0.29      1308
weighted avg       0.57      0.72      0.62      1308

Cohen's Kappa: 0.0081
2025-12-30 12:42:37.919796: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 12:48:24.416135: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 12:52:45.603712: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 9.
Epoch 29: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       250
           P       0.66      0.71      0.68       744
           R       0.22      0.52      0.31       147

    accuracy                           0.53      1141
   macro avg       0.29      0.41      0.33      1141
weighted avg       0.46      0.53      0.49      1141

Cohen's Kappa: 0.1470

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.6251 Â± 0.0966
  F1 Macro: 0.3104
  Kappa: 0.0776

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_3
Timestamp: 2025-12-30 12:58:05
Thresholds: I=87, P=77, R=87
================================================================================

2025-12-30 12:58:06.745583: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 12:58:06.745656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 12:58:06.747224: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 12:58:07.595574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 87, 'P': 77, 'R': 87}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=87, P=77, R=87

Excluded samples per class:
  Class I: 86 samples
  Class P: 90 samples
  Class R: 8 samples

Total unique samples to exclude: 184

Dataset size (rows): 3107 -> 2033 (65.4%)
Unique samples: 647 -> 463 (removed 184)

Class distribution after filtering:
  Class I: 424 rows
  Class P: 1312 rows
  Class R: 297 rows
============================================================

2025-12-30 12:58:23.719542: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 13:02:22.830590: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767099843.937515 1160290 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 13:06:10.139820: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.14      0.07      0.10       216
           P       0.61      0.84      0.70       623
           R       0.00      0.00      0.00       136

    accuracy                           0.55       975
   macro avg       0.25      0.30      0.27       975
weighted avg       0.42      0.55      0.47       975

Cohen's Kappa: 0.0285
2025-12-30 13:09:14.212490: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 13:12:58.539799: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 13:16:53.528719: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 10.
Epoch 30: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       208
           P       0.63      0.57      0.60       689
           R       0.17      0.46      0.25       161

    accuracy                           0.44      1058
   macro avg       0.27      0.34      0.28      1058
weighted avg       0.44      0.44      0.43      1058

Cohen's Kappa: 0.0625

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.4975 Â± 0.0543
  F1 Macro: 0.2752
  Kappa: 0.0455

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_4
Timestamp: 2025-12-30 13:21:20
Thresholds: I=82, P=85, R=94
================================================================================

2025-12-30 13:21:21.032633: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 13:21:21.032703: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 13:21:21.034295: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 13:21:21.892718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 82, 'P': 85, 'R': 94}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=82, P=85, R=94

Excluded samples per class:
  Class I: 137 samples
  Class P: 8 samples
  Class R: 0 samples

Total unique samples to exclude: 145

Dataset size (rows): 3107 -> 2373 (76.4%)
Unique samples: 647 -> 502 (removed 145)

Class distribution after filtering:
  Class I: 213 rows
  Class P: 1825 rows
  Class R: 335 rows
============================================================

2025-12-30 13:21:40.516538: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 13:26:47.822719: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767101308.804487 1299138 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 13:31:06.736308: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       108
           P       0.77      1.00      0.87       919
           R       0.00      0.00      0.00       169

    accuracy                           0.77      1196
   macro avg       0.26      0.33      0.29      1196
weighted avg       0.59      0.77      0.67      1196

Cohen's Kappa: 0.0000
2025-12-30 13:34:57.871925: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 13:40:07.371434: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 13:44:18.498122: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 11.
Epoch 31: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       105
           P       0.79      0.96      0.87       906
           R       0.39      0.16      0.22       166

    accuracy                           0.76      1177
   macro avg       0.39      0.37      0.36      1177
weighted avg       0.66      0.76      0.70      1177

Cohen's Kappa: 0.0817

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.7665 Â± 0.0019
  F1 Macro: 0.3265
  Kappa: 0.0409

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_5
Timestamp: 2025-12-30 13:49:54
Thresholds: I=81, P=96, R=98
================================================================================

2025-12-30 13:49:55.069675: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 13:49:55.069760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 13:49:55.071324: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 13:49:55.922328: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 81, 'P': 96, 'R': 98}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=81, P=96, R=98

Excluded samples per class:
  Class I: 145 samples
  Class P: 0 samples
  Class R: 0 samples

Total unique samples to exclude: 145

Dataset size (rows): 3107 -> 2401 (77.3%)
Unique samples: 647 -> 502 (removed 145)

Class distribution after filtering:
  Class I: 186 rows
  Class P: 1880 rows
  Class R: 335 rows
============================================================

2025-12-30 13:50:14.095580: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 13:55:23.232570: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767103020.962232 1443081 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 13:59:46.170700: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.42      0.04      0.08       119
           P       0.77      0.99      0.87       974
           R       0.00      0.00      0.00       175

    accuracy                           0.77      1268
   macro avg       0.40      0.34      0.31      1268
weighted avg       0.63      0.77      0.67      1268

Cohen's Kappa: 0.0360
2025-12-30 14:03:40.459198: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 14:09:22.655345: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 14:13:27.637848: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 11.
Epoch 31: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00        67
           P       0.81      0.97      0.88       906
           R       0.45      0.13      0.20       160

    accuracy                           0.80      1133
   macro avg       0.42      0.37      0.36      1133
weighted avg       0.71      0.80      0.74      1133

Cohen's Kappa: 0.1288

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.7809 Â± 0.0143
  F1 Macro: 0.3383
  Kappa: 0.0824

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_6
Timestamp: 2025-12-30 14:19:38
Thresholds: I=91, P=83, R=85
================================================================================

2025-12-30 14:19:39.007480: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 14:19:39.007556: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 14:19:39.009166: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 14:19:39.828617: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 91, 'P': 83, 'R': 85}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=91, P=83, R=85

Excluded samples per class:
  Class I: 50 samples
  Class P: 26 samples
  Class R: 21 samples

Total unique samples to exclude: 97

Dataset size (rows): 3107 -> 2537 (81.7%)
Unique samples: 647 -> 550 (removed 97)

Class distribution after filtering:
  Class I: 610 rows
  Class P: 1706 rows
  Class R: 221 rows
============================================================

2025-12-30 14:19:56.907270: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 14:25:02.594113: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767104801.757178 1587706 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 14:29:38.568190: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.46      0.04      0.08       277
           P       0.69      0.98      0.81       841
           R       0.00      0.00      0.00       113

    accuracy                           0.68      1231
   macro avg       0.38      0.34      0.30      1231
weighted avg       0.57      0.68      0.57      1231

Cohen's Kappa: 0.0417
2025-12-30 14:33:34.654807: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 14:38:32.950505: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 14:42:52.480578: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 14.
Epoch 34: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       333
           P       0.67      0.99      0.80       865
           R       0.48      0.13      0.20       108

    accuracy                           0.67      1306
   macro avg       0.38      0.37      0.33      1306
weighted avg       0.48      0.67      0.55      1306

Cohen's Kappa: 0.0500

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.6742 Â± 0.0073
  F1 Macro: 0.3154
  Kappa: 0.0459

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_7
Timestamp: 2025-12-30 14:48:33
Thresholds: I=90, P=61, R=90
================================================================================

2025-12-30 14:48:34.158632: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 14:48:34.158708: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 14:48:34.160340: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 14:48:35.015436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 90, 'P': 61, 'R': 90}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=90, P=61, R=90

Excluded samples per class:
  Class I: 63 samples
  Class P: 301 samples
  Class R: 0 samples

Total unique samples to exclude: 364

Dataset size (rows): 3107 -> 1140 (36.7%)
Unique samples: 647 -> 283 (removed 364)

Class distribution after filtering:
  Class I: 545 rows
  Class P: 260 rows
  Class R: 335 rows
============================================================

2025-12-30 14:48:48.921396: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 14:50:25.695453: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767106324.056018 1731683 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 14:53:31.378306: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 3.
Epoch 23: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.61      0.58      0.59       272
           P       0.18      0.46      0.26       114
           R       1.00      0.04      0.08       170

    accuracy                           0.39       556
   macro avg       0.60      0.36      0.31       556
weighted avg       0.64      0.39      0.37       556

Cohen's Kappa: 0.2535
2025-12-30 14:55:29.768781: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 14:57:04.438343: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 15:00:01.435878: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 18.
Epoch 38: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       273
           P       0.29      0.62      0.39       146
           R       0.21      0.35      0.26       165

    accuracy                           0.25       584
   macro avg       0.17      0.32      0.22       584
weighted avg       0.13      0.25      0.17       584

Cohen's Kappa: -0.1192

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.3219 Â± 0.0684
  F1 Macro: 0.2650
  Kappa: 0.0672

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_8
Timestamp: 2025-12-30 15:03:44
Thresholds: I=98, P=62, R=88
================================================================================

2025-12-30 15:03:44.774266: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 15:03:44.774342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 15:03:44.775922: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 15:03:45.617032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 98, 'P': 62, 'R': 88}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=98, P=62, R=88

Excluded samples per class:
  Class I: 0 samples
  Class P: 297 samples
  Class R: 3 samples

Total unique samples to exclude: 300

Dataset size (rows): 3107 -> 1489 (47.9%)
Unique samples: 647 -> 347 (removed 300)

Class distribution after filtering:
  Class I: 892 rows
  Class P: 272 rows
  Class R: 325 rows
============================================================

2025-12-30 15:03:59.795313: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 15:06:48.106343: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767107307.718917 1864269 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 15:09:59.401801: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.69      0.72      0.71       397
           P       0.17      0.34      0.23       132
           R       0.00      0.00      0.00       145

    accuracy                           0.49       674
   macro avg       0.29      0.35      0.31       674
weighted avg       0.44      0.49      0.46       674

Cohen's Kappa: 0.2766
2025-12-30 15:12:34.218081: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 15:14:55.475195: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 15:18:27.991658: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 1.
Epoch 21: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.79      0.21      0.33       495
           P       0.18      0.09      0.12       140
           R       0.22      0.77      0.35       180

    accuracy                           0.31       815
   macro avg       0.40      0.36      0.27       815
weighted avg       0.56      0.31      0.30       815

Cohen's Kappa: 0.0591

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.4027 Â± 0.0898
  F1 Macro: 0.2890
  Kappa: 0.1679

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_9
Timestamp: 2025-12-30 15:21:08
Thresholds: I=92, P=63, R=90
================================================================================

2025-12-30 15:21:09.304139: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 15:21:09.304221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 15:21:09.305784: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 15:21:10.145299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 92, 'P': 63, 'R': 90}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=92, P=63, R=90

Excluded samples per class:
  Class I: 37 samples
  Class P: 282 samples
  Class R: 0 samples

Total unique samples to exclude: 319

Dataset size (rows): 3107 -> 1354 (43.6%)
Unique samples: 647 -> 328 (removed 319)

Class distribution after filtering:
  Class I: 683 rows
  Class P: 336 rows
  Class R: 335 rows
============================================================

2025-12-30 15:21:23.812841: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 15:23:18.911708: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767108296.298673 1996504 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 15:26:40.313778: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.55      0.82      0.66       358
           P       0.21      0.23      0.22       166
           R       0.00      0.00      0.00       192

    accuracy                           0.46       716
   macro avg       0.25      0.35      0.29       716
weighted avg       0.32      0.46      0.38       716

Cohen's Kappa: 0.1357
2025-12-30 15:28:37.040381: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 15:30:51.867633: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 15:33:56.447054: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 32.
Epoch 52: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       325
           P       0.26      0.69      0.38       170
           R       0.26      0.35      0.30       143

    accuracy                           0.26       638
   macro avg       0.17      0.35      0.23       638
weighted avg       0.13      0.26      0.17       638

Cohen's Kappa: 0.0371

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.3613 Â± 0.0996
  F1 Macro: 0.2585
  Kappa: 0.0864

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_10
Timestamp: 2025-12-30 15:38:40
Thresholds: I=89, P=97, R=96
================================================================================

2025-12-30 15:38:41.403860: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 15:38:41.403935: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 15:38:41.405509: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 15:38:42.218081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 89, 'P': 97, 'R': 96}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=89, P=97, R=96

Excluded samples per class:
  Class I: 74 samples
  Class P: 0 samples
  Class R: 0 samples

Total unique samples to exclude: 74

Dataset size (rows): 3107 -> 2701 (86.9%)
Unique samples: 647 -> 573 (removed 74)

Class distribution after filtering:
  Class I: 486 rows
  Class P: 1880 rows
  Class R: 335 rows
============================================================

2025-12-30 15:39:00.770909: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 15:44:30.033242: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767109568.601422 2132146 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 15:48:56.194920: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.33      0.03      0.05       232
           P       0.72      0.99      0.83       939
           R       0.00      0.00      0.00       145

    accuracy                           0.71      1316
   macro avg       0.35      0.34      0.29      1316
weighted avg       0.57      0.71      0.60      1316

Cohen's Kappa: -0.0061
2025-12-30 15:52:50.409443: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 15:58:14.972901: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 16:02:49.095023: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 10.
Epoch 30: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       254
           P       0.70      0.83      0.76       941
           R       0.27      0.38      0.32       190

    accuracy                           0.61      1385
   macro avg       0.32      0.40      0.36      1385
weighted avg       0.51      0.61      0.56      1385

Cohen's Kappa: 0.1365

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.6640 Â± 0.0495
  F1 Macro: 0.3260
  Kappa: 0.0652

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_11
Timestamp: 2025-12-30 16:08:31
Thresholds: I=98, P=66, R=90
================================================================================

2025-12-30 16:08:32.322094: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 16:08:32.322169: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 16:08:32.323741: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 16:08:33.170610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 98, 'P': 66, 'R': 90}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=98, P=66, R=90

Excluded samples per class:
  Class I: 0 samples
  Class P: 250 samples
  Class R: 0 samples

Total unique samples to exclude: 250

Dataset size (rows): 3107 -> 1712 (55.1%)
Unique samples: 647 -> 397 (removed 250)

Class distribution after filtering:
  Class I: 892 rows
  Class P: 485 rows
  Class R: 335 rows
============================================================

2025-12-30 16:08:47.996861: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 16:11:21.460857: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767111184.152621 2276076 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 16:15:20.944091: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.59      0.65      0.62       493
           P       0.28      0.43      0.34       256
           R       0.00      0.00      0.00       190

    accuracy                           0.46       939
   macro avg       0.29      0.36      0.32       939
weighted avg       0.39      0.46      0.42       939

Cohen's Kappa: 0.1665
2025-12-30 16:17:51.072763: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 16:20:41.684676: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 16:24:07.823230: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 1.
Epoch 21: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.84      0.12      0.21       399
           P       0.22      0.05      0.08       229
           R       0.16      0.75      0.27       145

    accuracy                           0.22       773
   macro avg       0.41      0.31      0.19       773
weighted avg       0.53      0.22      0.19       773

Cohen's Kappa: 0.0146

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.3389 Â± 0.1190
  F1 Macro: 0.2544
  Kappa: 0.0906

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_12
Timestamp: 2025-12-30 16:27:03
Thresholds: I=93, P=60, R=94
================================================================================

2025-12-30 16:27:04.592777: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 16:27:04.592860: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 16:27:04.594465: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 16:27:05.443331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 93, 'P': 60, 'R': 94}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=93, P=60, R=94

Excluded samples per class:
  Class I: 28 samples
  Class P: 308 samples
  Class R: 0 samples

Total unique samples to exclude: 336

Dataset size (rows): 3107 -> 1290 (41.5%)
Unique samples: 647 -> 311 (removed 336)

Class distribution after filtering:
  Class I: 729 rows
  Class P: 226 rows
  Class R: 335 rows
============================================================

2025-12-30 16:27:19.957251: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 16:29:28.324800: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767112267.388567 2409200 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 16:32:43.553617: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.72      0.46      0.56       371
           P       0.11      0.45      0.18        91
           R       0.80      0.08      0.14       157

    accuracy                           0.36       619
   macro avg       0.54      0.33      0.29       619
weighted avg       0.65      0.36      0.40       619

Cohen's Kappa: 0.2697
2025-12-30 16:34:44.949632: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 16:37:11.453385: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 16:40:27.079522: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 13.
Epoch 33: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       358
           P       0.21      0.32      0.25       135
           R       0.19      0.50      0.28       178

    accuracy                           0.20       671
   macro avg       0.13      0.27      0.18       671
weighted avg       0.09      0.20      0.12       671

Cohen's Kappa: -0.1134

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.2793 Â± 0.0826
  F1 Macro: 0.2349
  Kappa: 0.0781

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_13
Timestamp: 2025-12-30 16:44:06
Thresholds: I=97, P=60, R=86
================================================================================

2025-12-30 16:44:07.136589: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 16:44:07.136667: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 16:44:07.138274: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 16:44:08.024892: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 97, 'P': 60, 'R': 86}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=97, P=60, R=86

Excluded samples per class:
  Class I: 2 samples
  Class P: 308 samples
  Class R: 14 samples

Total unique samples to exclude: 324

Dataset size (rows): 3107 -> 1363 (43.9%)
Unique samples: 647 -> 323 (removed 324)

Class distribution after filtering:
  Class I: 880 rows
  Class P: 226 rows
  Class R: 257 rows
============================================================

2025-12-30 16:44:22.015792: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 16:47:09.507117: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767113327.191682 2542049 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 16:50:20.698768: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 3.
Epoch 23: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.73      0.73      0.73       409
           P       0.17      0.37      0.23       101
           R       0.50      0.02      0.05       125

    accuracy                           0.54       635
   macro avg       0.47      0.37      0.34       635
weighted avg       0.59      0.54      0.52       635

Cohen's Kappa: 0.2342
2025-12-30 16:52:43.120382: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 16:55:20.183240: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 16:58:37.043973: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 1.
Epoch 21: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.80      0.28      0.42       471
           P       0.17      0.12      0.14       125
           R       0.14      0.50      0.22       132

    accuracy                           0.29       728
   macro avg       0.37      0.30      0.26       728
weighted avg       0.58      0.29      0.33       728

Cohen's Kappa: 0.0147

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.4140 Â± 0.1214
  F1 Macro: 0.2971
  Kappa: 0.1245

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_14
Timestamp: 2025-12-30 17:01:24
Thresholds: I=98, P=60, R=98
================================================================================

2025-12-30 17:01:25.403277: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 17:01:25.403355: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 17:01:25.404971: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 17:01:26.281194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 98, 'P': 60, 'R': 98}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=98, P=60, R=98

Excluded samples per class:
  Class I: 0 samples
  Class P: 308 samples
  Class R: 0 samples

Total unique samples to exclude: 308

Dataset size (rows): 3107 -> 1453 (46.8%)
Unique samples: 647 -> 339 (removed 308)

Class distribution after filtering:
  Class I: 892 rows
  Class P: 226 rows
  Class R: 335 rows
============================================================

2025-12-30 17:01:40.335227: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 17:04:41.025455: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767114378.034380 2672996 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 17:07:57.117591: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 1.
Epoch 21: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.61      0.93      0.74       409
           P       0.27      0.15      0.20       117
           R       0.00      0.00      0.00       163

    accuracy                           0.58       689
   macro avg       0.30      0.36      0.31       689
weighted avg       0.41      0.58      0.47       689

Cohen's Kappa: 0.0468
2025-12-30 17:10:13.987160: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 17:12:38.988000: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 17:15:57.602512: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 1.
Epoch 21: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.85      0.17      0.28       483
           P       0.04      0.03      0.03       109
           R       0.21      0.74      0.33       172

    accuracy                           0.28       764
   macro avg       0.37      0.31      0.22       764
weighted avg       0.59      0.28      0.26       764

Cohen's Kappa: 0.0375

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.4290 Â± 0.1515
  F1 Macro: 0.2639
  Kappa: 0.0422

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_15
Timestamp: 2025-12-30 17:18:35
Thresholds: I=98, P=60, R=85
================================================================================

2025-12-30 17:18:35.963081: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 17:18:35.963169: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 17:18:35.964791: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 17:18:37.013221: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 98, 'P': 60, 'R': 85}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=98, P=60, R=85

Excluded samples per class:
  Class I: 0 samples
  Class P: 308 samples
  Class R: 21 samples

Total unique samples to exclude: 329

Dataset size (rows): 3107 -> 1339 (43.1%)
Unique samples: 647 -> 318 (removed 329)

Class distribution after filtering:
  Class I: 892 rows
  Class P: 226 rows
  Class R: 221 rows
============================================================

2025-12-30 17:18:52.307649: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 17:21:28.730131: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767115389.728629 2801896 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 17:24:41.496690: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.72      0.90      0.80       418
           P       0.09      0.10      0.09       104
           R       0.00      0.00      0.00       114

    accuracy                           0.61       636
   macro avg       0.27      0.33      0.30       636
weighted avg       0.49      0.61      0.54       636

Cohen's Kappa: 0.2631
2025-12-30 17:27:02.385119: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 17:29:33.482381: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 17:32:51.888072: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 1.
Epoch 21: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.80      0.36      0.50       474
           P       0.12      0.07      0.09       122
           R       0.11      0.41      0.17       107

    accuracy                           0.32       703
   macro avg       0.34      0.28      0.25       703
weighted avg       0.58      0.32      0.38       703

Cohen's Kappa: 0.0274

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.4621 Â± 0.1449
  F1 Macro: 0.2744
  Kappa: 0.1453

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_16
Timestamp: 2025-12-30 17:35:30
Thresholds: I=95, P=97, R=98
================================================================================

2025-12-30 17:35:31.718194: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 17:35:31.718264: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 17:35:31.719751: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 17:35:32.587423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 95, 'P': 97, 'R': 98}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=95, P=97, R=98

Excluded samples per class:
  Class I: 10 samples
  Class P: 0 samples
  Class R: 0 samples

Total unique samples to exclude: 10

Dataset size (rows): 3107 -> 3055 (98.3%)
Unique samples: 647 -> 637 (removed 10)

Class distribution after filtering:
  Class I: 840 rows
  Class P: 1880 rows
  Class R: 335 rows
============================================================

2025-12-30 17:35:51.071157: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 17:41:14.166839: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767116577.298866 2930812 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 17:46:17.615181: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.21      0.03      0.05       409
           P       0.62      0.98      0.76       966
           R       0.00      0.00      0.00       213

    accuracy                           0.60      1588
   macro avg       0.28      0.34      0.27      1588
weighted avg       0.43      0.60      0.47      1588

Cohen's Kappa: -0.0509
2025-12-30 17:50:14.461593: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 17:55:45.233530: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 18:00:26.373280: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 12.
Epoch 32: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       431
           P       0.63      0.97      0.76       914
           R       0.10      0.05      0.07       122

    accuracy                           0.61      1467
   macro avg       0.24      0.34      0.28      1467
weighted avg       0.40      0.61      0.48      1467

Cohen's Kappa: -0.0185

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.6040 Â± 0.0020
  F1 Macro: 0.2724
  Kappa: -0.0347

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_17
Timestamp: 2025-12-30 18:06:18
Thresholds: I=98, P=68, R=98
================================================================================

2025-12-30 18:06:19.154479: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 18:06:19.154561: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 18:06:19.156003: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 18:06:19.984388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 98, 'P': 68, 'R': 98}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=98, P=68, R=98

Excluded samples per class:
  Class I: 0 samples
  Class P: 222 samples
  Class R: 0 samples

Total unique samples to exclude: 222

Dataset size (rows): 3107 -> 1859 (59.8%)
Unique samples: 647 -> 425 (removed 222)

Class distribution after filtering:
  Class I: 892 rows
  Class P: 632 rows
  Class R: 335 rows
============================================================

2025-12-30 18:06:34.473576: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 18:09:19.885451: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767118260.699615 3071228 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 18:13:01.245509: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 3.
Epoch 23: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.56      0.35      0.43       445
           P       0.33      0.66      0.44       319
           R       1.00      0.04      0.07       160

    accuracy                           0.40       924
   macro avg       0.63      0.35      0.31       924
weighted avg       0.56      0.40      0.37       924

Cohen's Kappa: 0.1796
2025-12-30 18:15:34.482901: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 18:18:27.480367: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 18:22:05.380072: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 30.
Epoch 50: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       447
           P       0.36      0.87      0.50       313
           R       0.05      0.05      0.05       175

    accuracy                           0.30       935
   macro avg       0.14      0.31      0.19       935
weighted avg       0.13      0.30      0.18       935

Cohen's Kappa: -0.1368

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.3510 Â± 0.0505
  F1 Macro: 0.2493
  Kappa: 0.0214

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_18
Timestamp: 2025-12-30 18:27:28
Thresholds: I=81, P=60, R=97
================================================================================

2025-12-30 18:27:28.761915: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 18:27:28.761994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 18:27:28.763572: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 18:27:29.610733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 81, 'P': 60, 'R': 97}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=81, P=60, R=97

Excluded samples per class:
  Class I: 145 samples
  Class P: 308 samples
  Class R: 0 samples

Total unique samples to exclude: 453

Dataset size (rows): 3107 -> 747 (24.0%)
Unique samples: 647 -> 194 (removed 453)

Class distribution after filtering:
  Class I: 186 rows
  Class P: 226 rows
  Class R: 335 rows
============================================================

2025-12-30 18:27:43.486550: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 18:29:02.150020: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767119440.897060 3206992 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 18:31:38.036021: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 3.
Epoch 23: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.29      0.35      0.32        91
           P       0.40      0.80      0.54       122
           R       0.00      0.00      0.00       137

    accuracy                           0.37       350
   macro avg       0.23      0.38      0.28       350
weighted avg       0.22      0.37      0.27       350

Cohen's Kappa: -0.0357
2025-12-30 18:33:17.992220: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 18:34:14.976269: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 18:36:47.518647: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 20.
Epoch 40: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00        95
           P       0.25      0.42      0.31       104
           R       0.39      0.43      0.41       198

    accuracy                           0.33       397
   macro avg       0.21      0.29      0.24       397
weighted avg       0.26      0.33      0.29       397

Cohen's Kappa: -0.2139

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.3480 Â± 0.0206
  F1 Macro: 0.2631
  Kappa: -0.1248

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_19
Timestamp: 2025-12-30 18:39:56
Thresholds: I=93, P=69, R=85
================================================================================

2025-12-30 18:39:56.778072: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 18:39:56.778151: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 18:39:56.779745: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 18:39:57.604752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 93, 'P': 69, 'R': 85}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=93, P=69, R=85

Excluded samples per class:
  Class I: 28 samples
  Class P: 208 samples
  Class R: 21 samples

Total unique samples to exclude: 257

Dataset size (rows): 3107 -> 1644 (52.9%)
Unique samples: 647 -> 390 (removed 257)

Class distribution after filtering:
  Class I: 729 rows
  Class P: 694 rows
  Class R: 221 rows
============================================================

2025-12-30 18:40:11.656964: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 18:42:29.526347: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767120247.538370 3335136 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 18:46:02.769629: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 4.
Epoch 24: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.57      0.31      0.40       344
           P       0.46      0.80      0.58       368
           R       0.00      0.00      0.00       120

    accuracy                           0.48       832
   macro avg       0.34      0.37      0.33       832
weighted avg       0.44      0.48      0.42       832

Cohen's Kappa: 0.1743
2025-12-30 18:48:35.519797: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 18:50:59.095118: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 18:54:24.888343: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 25.
Epoch 45: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       385
           P       0.40      0.86      0.54       326
           R       0.07      0.07      0.07       101

    accuracy                           0.35       812
   macro avg       0.15      0.31      0.20       812
weighted avg       0.17      0.35      0.23       812

Cohen's Kappa: -0.0268

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.4183 Â± 0.0649
  F1 Macro: 0.2657
  Kappa: 0.0738

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_20
Timestamp: 2025-12-30 18:59:21
Thresholds: I=98, P=88, R=98
================================================================================

2025-12-30 18:59:22.408122: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 18:59:22.408217: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 18:59:22.409867: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 18:59:23.266538: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 98, 'P': 88, 'R': 98}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=98, P=88, R=98

Excluded samples per class:
  Class I: 0 samples
  Class P: 4 samples
  Class R: 0 samples

Total unique samples to exclude: 4

Dataset size (rows): 3107 -> 3080 (99.1%)
Unique samples: 647 -> 643 (removed 4)

Class distribution after filtering:
  Class I: 892 rows
  Class P: 1853 rows
  Class R: 335 rows
============================================================

2025-12-30 18:59:41.711899: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 19:04:41.227952: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767121584.490027 3469327 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 19:09:51.129175: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.37      0.06      0.11       439
           P       0.60      0.96      0.74       976
           R       0.00      0.00      0.00       213

    accuracy                           0.59      1628
   macro avg       0.32      0.34      0.28      1628
weighted avg       0.46      0.59      0.47      1628

Cohen's Kappa: 0.0223
2025-12-30 19:13:49.124793: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 19:20:16.389725: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 19:25:13.209121: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 8.
Epoch 28: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       453
           P       0.61      0.91      0.73       877
           R       0.08      0.10      0.09       122

    accuracy                           0.56      1452
   macro avg       0.23      0.34      0.27      1452
weighted avg       0.38      0.56      0.45      1452

Cohen's Kappa: -0.0329

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.5770 Â± 0.0164
  F1 Macro: 0.2786
  Kappa: -0.0053

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_21
Timestamp: 2025-12-30 19:30:55
Thresholds: I=95, P=63, R=98
================================================================================

2025-12-30 19:30:56.007981: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 19:30:56.008061: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 19:30:56.009686: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 19:30:56.849192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 95, 'P': 63, 'R': 98}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=95, P=63, R=98

Excluded samples per class:
  Class I: 10 samples
  Class P: 282 samples
  Class R: 0 samples

Total unique samples to exclude: 292

Dataset size (rows): 3107 -> 1511 (48.6%)
Unique samples: 647 -> 355 (removed 292)

Class distribution after filtering:
  Class I: 840 rows
  Class P: 336 rows
  Class R: 335 rows
============================================================

2025-12-30 19:31:11.434470: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 19:33:46.630889: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767123329.435902 3609043 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 19:37:11.525537: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.67      0.59      0.63       410
           P       0.23      0.49      0.31       181
           R       0.00      0.00      0.00       151

    accuracy                           0.45       742
   macro avg       0.30      0.36      0.31       742
weighted avg       0.43      0.45      0.42       742

Cohen's Kappa: 0.2663
2025-12-30 19:39:41.228116: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 19:42:07.140591: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 19:45:30.655919: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 13.
Epoch 33: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       430
           P       0.26      0.64      0.37       155
           R       0.19      0.40      0.26       184

    accuracy                           0.22       769
   macro avg       0.15      0.35      0.21       769
weighted avg       0.10      0.22      0.14       769

Cohen's Kappa: -0.0987

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.3355 Â± 0.1106
  F1 Macro: 0.2620
  Kappa: 0.0838

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_22
Timestamp: 2025-12-30 19:49:17
Thresholds: I=81, P=98, R=85
================================================================================

2025-12-30 19:49:18.602660: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 19:49:18.602728: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 19:49:18.604311: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 19:49:19.428415: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 81, 'P': 98, 'R': 85}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=81, P=98, R=85

Excluded samples per class:
  Class I: 145 samples
  Class P: 0 samples
  Class R: 21 samples

Total unique samples to exclude: 166

Dataset size (rows): 3107 -> 2287 (73.6%)
Unique samples: 647 -> 481 (removed 166)

Class distribution after filtering:
  Class I: 186 rows
  Class P: 1880 rows
  Class R: 221 rows
============================================================

2025-12-30 19:49:37.203056: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 19:54:41.712191: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767124583.260760 3740476 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 19:59:01.376321: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 3.
Epoch 23: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       113
           P       0.82      1.00      0.90       978
           R       0.00      0.00      0.00       105

    accuracy                           0.82      1196
   macro avg       0.27      0.33      0.30      1196
weighted avg       0.67      0.82      0.74      1196

Cohen's Kappa: 0.0000
2025-12-30 20:03:02.364045: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 20:08:25.534922: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 20:12:29.794439: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 10.
Epoch 30: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00        73
           P       0.84      0.90      0.87       902
           R       0.26      0.28      0.27       116

    accuracy                           0.77      1091
   macro avg       0.37      0.39      0.38      1091
weighted avg       0.72      0.77      0.75      1091

Cohen's Kappa: 0.1757

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.7943 Â± 0.0234
  F1 Macro: 0.3395
  Kappa: 0.0878

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_23
Timestamp: 2025-12-30 20:18:24
Thresholds: I=95, P=60, R=98
================================================================================

2025-12-30 20:18:25.043147: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 20:18:25.043219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 20:18:25.044825: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 20:18:25.878414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 95, 'P': 60, 'R': 98}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=95, P=60, R=98

Excluded samples per class:
  Class I: 10 samples
  Class P: 308 samples
  Class R: 0 samples

Total unique samples to exclude: 318

Dataset size (rows): 3107 -> 1401 (45.1%)
Unique samples: 647 -> 329 (removed 318)

Class distribution after filtering:
  Class I: 840 rows
  Class P: 226 rows
  Class R: 335 rows
============================================================

2025-12-30 20:18:40.919692: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 20:21:19.028635: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767126176.357033 3878631 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 20:24:27.319532: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.67      0.75      0.71       408
           P       0.16      0.30      0.21       128
           R       0.00      0.00      0.00       157

    accuracy                           0.49       693
   macro avg       0.28      0.35      0.30       693
weighted avg       0.42      0.49      0.45       693

Cohen's Kappa: 0.2306
2025-12-30 20:26:51.326238: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 20:29:17.314261: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 20:32:32.390726: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 1.
Epoch 21: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.82      0.21      0.34       432
           P       0.04      0.03      0.03        98
           R       0.23      0.68      0.35       178

    accuracy                           0.30       708
   macro avg       0.36      0.31      0.24       708
weighted avg       0.56      0.30      0.30       708

Cohen's Kappa: 0.0444

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.3986 Â± 0.0949
  F1 Macro: 0.2714
  Kappa: 0.1375

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_24
Timestamp: 2025-12-30 20:35:10
Thresholds: I=96, P=60, R=91
================================================================================

2025-12-30 20:35:10.872836: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 20:35:10.872901: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 20:35:10.874410: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 20:35:11.741516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 96, 'P': 60, 'R': 91}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=96, P=60, R=91

Excluded samples per class:
  Class I: 6 samples
  Class P: 308 samples
  Class R: 0 samples

Total unique samples to exclude: 314

Dataset size (rows): 3107 -> 1416 (45.6%)
Unique samples: 647 -> 333 (removed 314)

Class distribution after filtering:
  Class I: 855 rows
  Class P: 226 rows
  Class R: 335 rows
============================================================

2025-12-30 20:35:25.915744: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 20:38:03.730790: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767127186.039112 4006682 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 20:41:22.101330: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 1.
Epoch 21: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.63      0.96      0.76       407
           P       0.27      0.16      0.20       114
           R       0.00      0.00      0.00       163

    accuracy                           0.60       684
   macro avg       0.30      0.37      0.32       684
weighted avg       0.42      0.60      0.49       684

Cohen's Kappa: 0.1042
2025-12-30 20:43:33.239806: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 20:45:59.981528: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 20:49:25.405225: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 1.
Epoch 21: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.90      0.13      0.22       448
           P       0.04      0.03      0.03       112
           R       0.21      0.72      0.33       172

    accuracy                           0.25       732
   macro avg       0.38      0.29      0.19       732
weighted avg       0.61      0.25      0.22       732

Cohen's Kappa: 0.0231

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.4239 Â± 0.1726
  F1 Macro: 0.2569
  Kappa: 0.0636

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_25
Timestamp: 2025-12-30 20:51:57
Thresholds: I=98, P=98, R=85
================================================================================

2025-12-30 20:51:58.319807: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 20:51:58.319878: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 20:51:58.321362: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 20:51:59.136590: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 45 (global batch size: 363, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Cross-validation: 2-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 363
  Per-GPU batch: 45 (363 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 11 files deleted
  Tf Cache: 4 files deleted
================================================================================

Misclassification filtering thresholds: {'I': 98, 'P': 98, 'R': 85}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=98, P=98, R=85

Excluded samples per class:
  Class I: 0 samples
  Class P: 0 samples
  Class R: 21 samples

Total unique samples to exclude: 21

Dataset size (rows): 3107 -> 2993 (96.3%)
Unique samples: 647 -> 626 (removed 21)

Class distribution after filtering:
  Class I: 892 rows
  Class P: 1880 rows
  Class R: 221 rows
============================================================

2025-12-30 20:52:17.448085: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 20:57:28.006553: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767128351.936303 4134701 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-30 21:02:34.466258: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 2.
Epoch 22: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.42      0.07      0.11       458
           P       0.64      0.96      0.77      1009
           R       0.00      0.00      0.00       124

    accuracy                           0.63      1591
   macro avg       0.35      0.34      0.29      1591
weighted avg       0.53      0.63      0.52      1591

Cohen's Kappa: 0.0388
2025-12-30 21:06:41.780102: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 21:12:45.393155: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-30 21:17:23.394150: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Restoring model weights from the end of the best epoch: 9.
Epoch 29: early stopping

Run 2 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00       434
           P       0.64      0.97      0.77       871
           R       0.12      0.09      0.11        97

    accuracy                           0.61      1402
   macro avg       0.25      0.35      0.29      1402
weighted avg       0.40      0.61      0.49      1402

Cohen's Kappa: -0.0390

All results saved to /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv

================================================================================
FINAL SUMMARY - BEST MODALITY COMBINATIONS
================================================================================

Best by Accuracy:
  Modalities: metadata+depth_rgb+depth_map+thermal_map
  Accuracy: 0.6195 Â± 0.0097
  F1 Macro: 0.2927
  Kappa: -0.0001

Total combinations tested: 1
================================================================================


================================================================================
EVALUATION EVAL_26
Timestamp: 2025-12-30 21:23:10
Thresholds: I=95, P=60, R=85
================================================================================

2025-12-30 21:23:11.727390: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-30 21:23:11.727472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-30 21:23:11.729051: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-30 21:23:12.597252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)
