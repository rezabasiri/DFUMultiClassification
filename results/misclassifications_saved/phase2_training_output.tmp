2025-12-28 06:28:23.699397: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-28 06:28:23.699555: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-28 06:28:23.701130: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-28 06:28:24.442306: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 2 GPU(s):
  GPU 0: NVIDIA GeForce RTX 5090 - 31.8GB
  GPU 1: NVIDIA GeForce RTX 5090 - 31.8GB

Selected 2 GPU(s):
  GPU 0: NVIDIA GeForce RTX 5090 (31.8GB)
  GPU 1: NVIDIA GeForce RTX 5090 (31.8GB)
2025-12-28 06:28:28.653620: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-12-28 06:28:28.656024: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Enabled memory growth for 2 GPU(s)
2025-12-28 06:28:28.954890: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-12-28 06:28:28.956593: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.

Using MirroredStrategy (2 GPUs) with ReductionToOneDevice
  (GPU-based gradient aggregation, NCCL-free for RTX 5090 compatibility)
Effective batch size: 2Ã— global batch size
================================================================================


Batch size per replica: 8 (global batch size: 16, replicas: 2)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 100.0%
Verbosity: 0 (MINIMAL)
Device: GPUs [0, 1] (multi-GPU mode, MirroredStrategy)
  Replicas: 2Ã— batch size distribution
Cross-validation: 3-fold CV (patient-level)

Configuration loaded from: src/utils/production_config.py
Image size: 128x128
Batch size: 16
  Per-GPU batch: 8 (16 / 2 GPUs)
Max epochs: 150 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Csv Results: 1 files deleted
  Tf Cache: 4 files deleted
================================================================================

2025-12-28 06:28:29.980753: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-12-28 06:28:29.982699: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Misclassification filtering thresholds: {'I': 3, 'P': 5, 'R': 5}

============================================================
FILTERING SUMMARY
============================================================
Thresholds: I=3, P=5, R=5

Excluded samples per class:
  Class I: 125 samples
  Class P: 0 samples
  Class R: 0 samples

Total unique samples to exclude: 125

Dataset size (rows): 3107 -> 2512 (80.8%)
Unique samples: 647 -> 522 (removed 125)

Class distribution after filtering:
  Class I: 297 rows
  Class P: 1880 rows
  Class R: 335 rows
============================================================

2025-12-28 06:28:37.912165: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
