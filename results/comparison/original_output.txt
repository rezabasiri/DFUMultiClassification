STDOUT:
Custom configs: {'test_0': {'modalities': ['metadata']}, 'test_1': {'modalities': ['depth_rgb']}, 'test_2': {'modalities': ['depth_map']}}
Starting original code execution...
Number of samples for each selected modality:
  depth_rgb: 3107
  depth_bb: 3107
  depth_map: 3107
  metadata: 3107

Starting cross-validation...

Run 1/1

Loaded aggregated predictions for run 1
Number of models: 1
Shape of predictions from first model: (2514, 3)
Labels shape: (2514,)
Found incomplete set of predictions (1 of 3)
Processing metadata shape...
Warning: Could not find optimal split after 2000 attempts.
Using best found split with max difference of 0.082

Best found class distributions:
Training: {0: 0.286, 1: 0.607, 2: 0.107}
Validation: {0: 0.356, 1: 0.525, 2: 0.119}

Unique cases: 189 (before oversampling)

True binary label distributions (unique cases):
Binary1: label_bin1
1    133
0     56
Name: count, dtype: int64
Binary2: label_bin2
0    169
1     20
Name: count, dtype: int64
Original class distribution (ordered):
Class 0: 72
Class 1: 153
Class 2: 27

Calculated alpha values from original distribution:
Alpha values (ordered) [I, P, R]: [0.725, 0.341, 1.934]
Using Scikit-learn RandomForestClassifier
Healing Phase Abs type: <class 'numpy.ndarray'> shape: (252,)
Healing Phase Abs type: <class 'numpy.ndarray'> shape: (59,)
Setting image shapes...
Removed cache file: /workspace/DFUMultiClassification/results/tf_cache_train.data-00000-of-00001
Removed cache file: /workspace/DFUMultiClassification/results/tf_cache_train.index

Preparing datasets for run 1 with all modalities: ['depth_map', 'depth_rgb', 'metadata']
Warning: Could not find optimal split after 2000 attempts.
Using best found split with max difference of 0.082

Best found class distributions:
Training: {0: 0.286, 1: 0.607, 2: 0.107}
Validation: {0: 0.356, 1: 0.525, 2: 0.119}

Unique cases: 189 (before oversampling)

True binary label distributions (unique cases):
Binary1: label_bin1
1    133
0     56
Name: count, dtype: int64
Binary2: label_bin2
0    169
1     20
Name: count, dtype: int64
Original class distribution (ordered):
Class 0: 72
Class 1: 153
Class 2: 27

Calculated alpha values from original distribution:
Alpha values (ordered) [I, P, R]: [0.725, 0.341, 1.934]
Using Scikit-learn RandomForestClassifier
Healing Phase Abs type: <class 'numpy.ndarray'> shape: (252,)
depth_map type: <class 'numpy.ndarray'> shape: (252,)
depth_rgb type: <class 'numpy.ndarray'> shape: (252,)
Healing Phase Abs type: <class 'numpy.ndarray'> shape: (59,)
depth_map type: <class 'numpy.ndarray'> shape: (59,)
depth_rgb type: <class 'numpy.ndarray'> shape: (59,)

No existing data found for test_0, starting fresh

Training test_0 with modalities: ['metadata'], run 1 of 1
Error during training: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} /workspace/DFUMultiClassification/results/tf_cache_train_0.data-00000-of-00001.tempstate14556291132624278791; No such file or directory [Op:IteratorGetNext] name: 
Error during training: cannot access local variable 'alpha_value' where it is not associated with a value
Error during training: cannot access local variable 'alpha_value' where it is not associated with a value

No existing data found for test_1, starting fresh

Training test_1 with modalities: ['depth_rgb'], run 1 of 1
Alpha values (ordered) [I, P, R]: [0.725, 0.341, 1.934]
Class weights: {0: 1, 1: 1, 2: 1} or [1, 1, 1]

Debug create_image_branch
No existing pretrained weights found
Total model trainable weights: 27
Restoring model weights from the end of the best epoch: 72.
Epoch 92: early stopping

Run 1 Results for test_1:
              precision    recall  f1-score   support

           I       0.00      0.00      0.00        21
           P       0.53      1.00      0.70        31
           R       0.00      0.00      0.00         7

    accuracy                           0.53        59
   macro avg       0.18      0.33      0.23        59
weighted avg       0.28      0.53      0.37        59

Cohen's Kappa: -0.0518

No existing data found for test_2, starting fresh

Training test_2 with modalities: ['depth_map'], run 1 of 1
Alpha values (ordered) [I, P, R]: [1, 1, 1]
Class weights: {0: 1.1666666666666667, 1: 0.5490196078431373, 2: 3.111111111111111} or [1.16666667 0.54901961 3.11111111]

Debug create_image_branch
No existing pretrained weights found
Total model trainable weights: 25
Restoring model weights from the end of the best epoch: 48.
Epoch 68: early stopping

Run 1 Results for test_2:
              precision    recall  f1-score   support

           I       0.36      1.00      0.53        21
           P       1.00      0.03      0.06        31
           R       0.00      0.00      0.00         7

    accuracy                           0.37        59
   macro avg       0.45      0.34      0.20        59
weighted avg       0.65      0.37      0.22        59

Cohen's Kappa: 0.0081
Results saved to /workspace/DFUMultiClassification/results/modality_results_averaged.csv

Original code execution complete!
Metrics: []


STDERR:
2025-12-21 20:29:12.009570: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-21 20:29:12.009855: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-21 20:29:12.011251: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-21 20:29:12.019928: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-12-21 20:29:12.846433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-12-21 20:29:16.345591: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-12-21 20:29:16.360679: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-12-21 20:29:16.516235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 25026 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5090, pci bus id: 0000:c1:00.0, compute capability: 12.0
2025-12-21 20:29:22.464184: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-21 20:29:40.894207: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-21 20:29:55.947891: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-21 20:30:13.195961: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-21 20:30:30.757769: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-21 20:30:34.593983: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902
2025-12-21 20:30:36.891632: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f8eb5c53940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-12-21 20:30:36.891696: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 5090, Compute Capability 12.0
2025-12-21 20:30:36.897996: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1766349037.008457 1778654 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-12-21 20:30:44.439347: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-21 20:30:50.765317: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-21 20:31:01.427239: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2025-12-21 20:31:07.334247: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
