# DFU Multi-Classification

Multimodal deep learning for Diabetic Foot Ulcer (DFU) healing phase classification using the GAMAN (Generative Adaptive Multimodal Attention Network) architecture.

## Overview

This project implements a multimodal classification system for DFU healing phases (Inflammatory, Proliferative, Remodeling) using:
- Clinical metadata
- RGB imaging
- Thermal imaging
- Depth sensing

## Key Features

- **GAMAN Architecture**: Dynamic late fusion with hierarchical attention mechanisms
- **Phase-Specific Classification**: Three-class healing phase classification
- **Multimodal Integration**: Combines multiple imaging modalities with clinical data
- **Ensemble Framework**: Adaptive phase weighting for improved performance

## System Components

### Multimodal Fusion (GAMAN)
The core model that combines different input modalities (metadata, depth images, thermal images) within a single neural network. Each modality is processed through its own branch, then fused using attention mechanisms to produce a single prediction. This is **early/intermediate fusion** where features are combined during model training.

### Gating Network (Late Fusion Ensemble)
A meta-learning component that combines predictions from multiple models trained on **different modality combinations**. For example:
- Model A: trained on `[metadata, depth_rgb]`
- Model B: trained on `[metadata, depth_rgb, thermal_map]`
- Model C: trained on `[depth_rgb, depth_map]`

The gating network learns which "expert" model to trust for each sample, creating an ensemble that outperforms individual models. This is **late fusion** where complete models are ensembled after training.

### Search Mode
An exploration tool that systematically tests all possible modality combinations (31 combinations from 5 modalities) to identify which combinations perform best. Each combination is trained and evaluated independently, with results saved to CSV for comparison.

**Usage:**
```bash
python src/main.py --mode search --data_percentage 100 --n_runs 3
```

### Cross-Validation
Patient-level splitting ensures no data leakage between training and validation sets. Multiple runs with different random splits provide robust performance estimates with confidence intervals.

## Project Structure

```
DFUMultiClassification/
├── src/                    # Source code
│   ├── main.py            # Main training script
│   ├── data/              # Data processing modules
│   ├── models/            # Model architectures & losses
│   ├── training/          # Training utilities
│   ├── evaluation/        # Metrics & visualization
│   └── utils/             # Configuration & utilities
├── data/                  # Data directory
│   ├── raw/               # Raw images & CSV files
│   └── processed/         # Processed data
├── paper/                 # Research paper (LaTeX)
├── docs/                  # Documentation
├── scripts/               # Standalone scripts
└── archive/               # Archived/unused code
```

## Installation

1. **Clone the repository:**
```bash
git clone https://github.com/rezabasiri/DFUMultiClassification.git
cd DFUMultiClassification
```

2. **Create and activate a virtual environment:**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

## Data Structure

### Image Filename Format

All image filenames follow a standardized format:

```
{random_number}_P{patient#:3d}{appt#:2d}{dfu#:1d}{B/A}{D/T}{R/M/L}{Z/W}.png
```

**Components:**
- `random_number`: Random identifier (varies)
- `P`: Prefix for patient data
- `patient#`: 3-digit patient number (e.g., 257, 087, 053)
- `appt#`: 2-digit appointment number, starting from 00
- `dfu#`: 1-digit DFU (wound) number, starting from 1
- `B/A`: Debridement status - **B**efore or **A**fter debridement
- `D/T`: Camera source - **D**epth camera or **T**hermal camera
- `R/M/L`: Angle - **R**ight, **M**iddle, or **L**eft
- `Z/W`: View type - **Z**oomed (close-up) or **W**ide angle

**Examples:**
- `10_P257001ADMW.png` → Patient 257, Appt 00, DFU 1, **A**fter debridement, **D**epth camera, **M**iddle angle, **W**ide view
- `14_P087031BDMZ.png` → Patient 87, Appt 03, DFU 1, **B**efore debridement, **D**epth camera, **M**iddle angle, **Z**oomed view
- `6_P219002ATMZ.png` → Patient 219, Appt 00, DFU 2, **A**fter debridement, **T**hermal camera, **M**iddle angle, **Z**oomed view

### Dataset Files

- `DataMaster_Processed_V12_WithMissing.csv`: Complete clinical and metadata records
- `best_matching.csv`: Matched image-to-metadata mappings (generated by preprocessing)
- `bounding_box_depth.csv`: Depth image bounding boxes for wound region
- `bounding_box_thermal.csv`: Thermal image bounding boxes for wound region

### Healing Phase Labels

The `Healing Phase Abs` column contains three classes:
- **I**: Inflammatory phase (initial wound response)
- **P**: Proliferative phase (tissue formation)
- **R**: Remodeling phase (maturation and healing)

## Quick Start

### 1. Setup
```bash
# Configure paths in src/utils/config.py for your environment
# Place your data in data/raw/ directory with proper structure
```

### 2. Explore Modality Combinations (Search Mode)
Test all modality combinations to find the best performers:
```bash
# Full exploration with 3 cross-validation runs
python src/main.py --mode search --data_percentage 100 --n_runs 3

# Quick test with 5% of data
python src/main.py --mode search --data_percentage 5 --n_runs 1
```

Results saved to: `results/csv/modality_combination_results.csv`

### 3. Train Gating Network Ensemble
After identifying top-performing combinations from search mode:

1. Edit `src/utils/production_config.py` to set your chosen combinations:
   ```python
   INCLUDED_COMBINATIONS = [
       ('metadata', 'depth_rgb'),
       ('metadata', 'depth_rgb', 'thermal_map'),
       ('depth_rgb', 'depth_map'),
   ]
   ```

2. Run search mode - this will train all combinations and automatically run the gating network:
   ```bash
   python src/main.py --mode search --data_percentage 100 --n_runs 3
   ```

The gating network will ensemble predictions from all trained models.

## Demo & Testing

The `demo/` directory contains test scripts to validate the pipeline:

- **`demo/test_workflow.py`**: Basic end-to-end test with minimal data
- **`demo/test_modality_combinations.py`**: Comprehensive test of all 31 modality combinations (1-5 modalities)
  - Tests the dynamic modality system
  - Generates performance analysis comparing all combinations
  - Saves detailed results to `modality_test_results_*.txt`

Run tests: `python demo/test_modality_combinations.py`

## Paper

The research paper is available in the `paper/` directory. See `paper/main.tex` for the full manuscript.

## Citation

If you use this code, please cite the associated paper on Multimodal Healing Phase Classification of DFU.

## License

See LICENSE file for details.
