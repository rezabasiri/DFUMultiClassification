# AI Agent Handoff Document
**Project:** DFUMultiClassification - Diabetic Foot Ulcer Wound Classification
**Session Date:** 2026-01-25
**Branch:** `claude/run-dataset-polishing-X1NHe`
**Last Commit:** fc58cb4

---

## üìã Project Overview

### Purpose
Multi-modal machine learning system for classifying diabetic foot ulcer (DFU) wounds into three healing phases:
- **Phase I:** Inflammatory
- **Phase P:** Proliferative
- **Phase R:** Remodeling

### Modalities Supported
1. **depth_rgb** - Depth camera RGB images
2. **thermal_rgb** - Thermal camera RGB visualizations
3. **depth_map** - Depth sensor map data
4. **thermal_map** - Thermal sensor map data
5. **metadata** - Clinical metadata (wound size, age, etc.)

### Key Technology Stack
- **Deep Learning:** TensorFlow 2.x, Keras
- **Generative Models:** PyTorch, Diffusers (Stable Diffusion XL)
- **Compute:** Multi-GPU training with CUDA
- **Python Environment:** Conda environment named `multimodal`
- **GPU Requirements:** 24GB+ VRAM recommended for SDXL

---

## üéØ Recent Work Completed

### SDXL Generative Augmentation Migration (Main Task)

Successfully migrated SDXL-based generative augmentation system from experimental directory to production:

**What Was Done:**
1. ‚úÖ Copied utility files to `src/utils/`:
   - `checkpoint_utils.py` - Checkpoint management
   - `generative_data_loader.py` - Bbox-aware data loading
   - `quality_metrics.py` - FID, SSIM, LPIPS, IS metrics
   - `generative_training_utils.py` - EMA, perceptual loss
   - `full_sdxl_config.yaml` - SDXL training configuration

2. ‚úÖ Created new integration code:
   - `src/data/generative_augmentation_sdxl.py` - Production SDXL system
   - Replaces old `src/data/generative_augmentation_v2.py` (SD 1.5 LoRA)
   - Implements lazy loading to prevent resource exhaustion
   - Reduces PyTorch thread usage (`torch.set_num_threads(2)`)

3. ‚úÖ Created comprehensive documentation:
   - `GENERATIVE_AUGMENTATION_MIGRATION_GUIDE.md` - Technical overview
   - `LOCAL_AGENT_MIGRATION_INSTRUCTIONS.md` - Step-by-step guide

4. ‚úÖ Fixed critical issues:
   - Thread exhaustion error (EAGAIN) - Fixed with lazy loading
   - Missing checkpoint handling - Graceful fallback with warnings
   - Resource competition between PyTorch and TensorFlow

**Key Improvements:**
- **Old System:** SD 1.5 LoRA (~500MB, 11.5% params trainable)
- **New System:** SDXL full fine-tune (~10GB, 100% params trainable)
- **Quality:** FID improved from ~300-400 to ~190-255
- **Efficiency:** Generates directly at target size (no resizing)
- **Training:** Phase-specific with minimal prompts, bbox-cropped data

---

## üìÅ Critical Files & Locations

### Main Training Script
```
src/main.py (119KB, 3.9K lines)
```
- Multi-modal transformer-based classification
- Handles data loading, augmentation, training, evaluation
- Supports multi-GPU training via strategy pattern
- **Already updated** to import from `generative_augmentation_sdxl`

### Generative Augmentation System
```
src/data/generative_augmentation_sdxl.py (27KB, 754 lines)
```
- **Status:** Production-ready with lazy loading
- **Location:** Integrated into main project
- **Checkpoints:** Expected at `src/models/sdxl_checkpoints/`
- **Config:** `src/utils/full_sdxl_config.yaml`

**Key Classes:**
- `SDXLWoundGenerator` - Loads checkpoints, generates images
- `GenerativeAugmentationManager` - Manages generator lifecycle, lazy loading
- `AugmentationConfig` - Configuration for all augmentation types

### Configuration Files
```
src/utils/production_config.py
```
- `USE_GENERATIVE_AUGMENTATION = True` - Enable/disable SDXL
- `GENERATIVE_AUG_MODEL_PATH = 'src/models/sdxl_checkpoints'`
- `GENERATIVE_AUG_PROB = 0.3` - 30% chance of generative aug
- `GENERATIVE_AUG_MIX_RATIO = (0.2, 0.4)` - Replace 20-40% of batch
- `GENERATIVE_AUG_INFERENCE_STEPS = 50` - SDXL diffusion steps
- `GENERATIVE_AUG_BATCH_LIMIT = 8` - Max images per generation
- `IMAGE_SIZE = 256` - Standard image size (can vary)

```
src/utils/full_sdxl_config.yaml
```
- SDXL training configuration
- Phase-specific prompts (minimal design)
- Guidance scale: 4.0 (reduced from 12.0)
- Resolution: 512√ó512 native

### Checkpoint Location
```
src/models/sdxl_checkpoints/
‚îú‚îÄ‚îÄ checkpoint_epoch_0030.pt (~10GB) - Best by metrics
‚îú‚îÄ‚îÄ checkpoint_epoch_0035.pt (~10GB) - Latest
‚îú‚îÄ‚îÄ checkpoint_best.pt -> checkpoint_epoch_0030.pt (symlink)
‚îú‚îÄ‚îÄ checkpoint_latest.pt -> checkpoint_epoch_0035.pt (symlink)
‚îî‚îÄ‚îÄ checkpoint_history.json
```

**Note:** The large `.pt` files are in `.gitignore` - NOT synced to git

### Experimental Directory (DO NOT MODIFY)
```
agent_communication/generative_augmentation/
```
- Original SDXL training code
- Training logs and sample images
- Should remain untouched per user request

---

## üîß Environment Setup

### Conda Environment
```bash
source /opt/miniforge3/bin/activate multimodal
```

### Key Packages
- **TensorFlow:** 2.x with CUDA support
- **PyTorch:** Latest with CUDA support
- **Diffusers:** For SDXL pipeline
- **Transformers:** Hugging Face models
- **Accelerate:** For distributed training
- **scikit-learn, pandas, numpy, matplotlib**

### GPU Configuration
- Multi-GPU support via TensorFlow distributed strategy
- Device mode: `multi` (default)
- Recommended: 24GB+ VRAM per GPU for SDXL
- Thread limits applied to prevent exhaustion

---

## üß™ Testing & Validation

### Quick Test Command
```bash
cd /workspace/DFUMultiClassification
source /opt/miniforge3/bin/activate multimodal
python agent_communication/generative_augmentation/test_generative_aug.py --quick --fresh
```

**Test Status:**
- ‚ö†Ô∏è **Last run had thread exhaustion error** (before lazy loading fix)
- ‚úÖ **Should now work** with lazy loading implementation
- üîÑ **Needs validation** - User should run test again

### Expected Test Behavior
With lazy loading:
1. **Startup:** Fast, no SDXL loading
2. **Training begins:** TensorFlow has full resources
3. **First generation:** SDXL loads on-demand with message: "Loading SDXL generator (first use)..."
4. **Subsequent generations:** Reuses loaded pipeline

Without checkpoints (graceful fallback):
```
WARNING: No checkpoint .pt files found in src/models/sdxl_checkpoints
Generative augmentation will be disabled until checkpoints are available
```

### Full Test Command
```bash
python agent_communication/generative_augmentation/test_generative_aug.py --fresh
```
Runs baseline vs generative augmentation comparison.

---

## üêõ Known Issues & Solutions

### Issue 1: Thread Creation Failure (SOLVED)
**Symptom:**
```
F external/local_tsl/tsl/platform/default/env.cc:74]
Check failed: ret == 0 (11 vs. 0)Thread tf_ creation via pthread_create() failed.
```

**Root Cause:** SDXL loading immediately consumed too many threads/resources

**Solution Applied:**
- Lazy loading: SDXL loads only on first generation request
- Reduced PyTorch threads: `torch.set_num_threads(2)`
- Graceful fallback if checkpoints missing

**Status:** ‚úÖ Fixed in latest code

### Issue 2: Missing Checkpoints
**Symptom:** Checkpoints exist locally but aren't in git (by design)

**Solution:**
- Checkpoints are in `.gitignore` (too large for git)
- Local agent has copied them to `src/models/sdxl_checkpoints/`
- Code handles missing checkpoints gracefully

**Status:** ‚úÖ Expected behavior, handled correctly

### Issue 3: Large Git History
**Symptom:** `.git` directory is 1.5GB

**Cause:** History includes 172 deleted PNG files from `data/raw/`

**Solution (Optional):**
```bash
git gc --aggressive --prune=now
```

**Status:** ‚ö†Ô∏è Not critical, cosmetic issue

---

## üìä Data Structure

### Dataset Location
```
data/raw/
‚îú‚îÄ‚îÄ Depth_Map_IMG/        (27M remaining)
‚îú‚îÄ‚îÄ Thermal_Map_IMG/      (16M remaining)
‚îú‚îÄ‚îÄ bounding_box_depth.csv
‚îú‚îÄ‚îÄ bounding_box_thermal.csv
‚îî‚îÄ‚îÄ DataMaster_Processed_V12_WithMissing.csv
```

**Note:** 172 RGB image files (Depth_RGB, Thermal_RGB) were deleted in recent commits to reduce repo size.

### Cleaned Data
```
data/cleaned/
‚îú‚îÄ‚îÄ depth_rgb_thermal_map_15pct.csv (1.1M)
‚îú‚îÄ‚îÄ metadata_thermal_map_15pct.csv (1.2M)
‚îî‚îÄ‚îÄ depth_map_depth_rgb_metadata_thermal_map_15pct.csv (1.1M)
```

### Cache Files
```
cache_outlier/
```
- Feature cache `.npy` files (recently deleted in latest pull)
- Regenerated automatically during training
- Can be added to `.gitignore` if desired

---

## üöÄ How to Run Training

### Full Training with Generative Augmentation
```bash
source /opt/miniforge3/bin/activate multimodal
cd /workspace/DFUMultiClassification

# With generative augmentation (if checkpoints available)
python src/main.py \
  --modality depth_rgb metadata \
  --device-mode multi \
  --resume_mode fresh

# Baseline without generative augmentation
python src/main.py \
  --modality depth_rgb metadata \
  --device-mode multi \
  --resume_mode fresh \
  --no_gen_aug
```

### Quick Test (50% data, 50 epochs, 64x64 images)
```bash
python agent_communication/generative_augmentation/test_generative_aug.py --quick
```

### With Specific Data Percentage
```bash
python src/main.py \
  --modality depth_rgb \
  --data_percentage 15.0 \
  --device-mode multi
```

---

## üîç Code Architecture

### Main Pipeline Flow
1. **Data Loading** (`src/data/dataset_utils.py`)
   - Load CSV with bounding boxes
   - Load images from modality directories
   - Apply bbox cropping

2. **Augmentation** (`src/data/generative_augmentation_sdxl.py`)
   - Regular augmentations (brightness, contrast, noise)
   - **Generative augmentation (SDXL):**
     - Check if should generate (30% probability)
     - Lazy-load SDXL generator if needed
     - Generate phase-specific wound images
     - Mix with real data (20-40% replacement)

3. **Model Architecture** (`src/models/`)
   - Modality-specific feature extractors (EfficientNet, CNN)
   - Multimodal fusion layer
   - Transformer encoder for cross-modal attention
   - Classification head (3 classes: I, P, R)

4. **Training** (`src/main.py`)
   - K-fold cross-validation (3 folds)
   - Early stopping, learning rate reduction
   - Multi-GPU distributed training
   - Metrics: Accuracy, F1, Cohen's Kappa

5. **Evaluation** (`src/evaluation/`)
   - Confusion matrices
   - Per-phase metrics
   - Feature importance (SHAP)

### Generative Augmentation Lifecycle

**Lazy Loading Pattern:**
```python
# Initialization (startup) - No SDXL loaded
manager = GenerativeAugmentationManager(
    checkpoint_dir='src/models/sdxl_checkpoints',
    config=aug_config
)
# Only stores paths, doesn't load SDXL

# First generation request - SDXL loads here
manager.generate_images(modality='depth_rgb', phase='I', batch_size=4)
# Calls _ensure_generator_loaded() -> loads SDXL pipeline

# Subsequent requests - Reuses loaded pipeline
manager.generate_images(modality='depth_rgb', phase='P', batch_size=4)
# Uses cached generator
```

---

## üìà Performance Metrics

### SDXL Training Results (Epochs 30-38)
- **FID:** 189-255 (target <50, improving)
- **SSIM:** 0.80-0.90 ‚úì (target >0.7)
- **LPIPS:** 0.40-0.57 (target <0.3)
- **Inception Score:** 2.4-3.0 ‚úì (target >2.0)

**Phase-Specific Quality:**
```
Phase I (Inflammatory):  SSIM=0.84, LPIPS=0.47
Phase P (Proliferative): SSIM=0.85, LPIPS=0.45
Phase R (Remodeling):    SSIM=0.88, LPIPS=0.37
```

### Classification Baseline (from test logs)
**Without Generative Augmentation:**
- Cohen's Kappa: 0.1981
- Accuracy: 0.6063

**With Generative Augmentation:**
- Test interrupted (thread error) - needs retest with lazy loading fix

---

## üéì Key Technical Concepts

### SDXL vs SD 1.5
| Aspect | SD 1.5 LoRA (Old) | SDXL Full (New) |
|--------|-------------------|-----------------|
| Parameters | 850M (11.5% trainable) | 2.6B (100% trainable) |
| Checkpoint Size | ~500MB | ~10GB |
| Resolution | 256√ó256 | 512√ó512 native |
| Quality | FID ~300-400 | FID ~190-255 |
| Prompts | Detailed descriptions | Minimal phase prompts |
| Training Data | Mixed sources | 100% bbox-cropped |

### Phase-Specific Prompts (Minimal Design)
```yaml
phase_prompts:
  I: "PHASE_I, diabetic foot ulcer, inflammatory phase wound"
  P: "PHASE_P, diabetic foot ulcer, proliferative phase wound"
  R: "PHASE_R, diabetic foot ulcer, remodeling phase wound"
```

**Why minimal?** Forces model to learn from training data rather than relying on SDXL's pretrained knowledge.

### Lazy Loading Pattern
Prevents resource exhaustion by deferring expensive model loading:
1. Store paths during initialization
2. Load model only when first needed
3. Cache loaded model for subsequent use
4. Thread-safe with locks

---

## üìù Git Workflow

### Current Branch
```
claude/run-dataset-polishing-X1NHe
```

### Recent Commits
```
fc58cb4 - Remove cache_outlier .npy files, update .gitignore
95884ca - Remove cached raw image files
591c37b - fix: Lazy-load SDXL and reduce thread usage
4a08289 - fix: Handle missing SDXL checkpoints gracefully
2cc8e9e - feat: Migrate SDXL generative augmentation to main project
```

### Important .gitignore Entries
```
*.pt
*.pth
*.ckpt
*.safetensors
cache_outlier/*.npy
data/raw/Depth_RGB/*.png
data/raw/Thermal_RGB/*.png
```

### Commit Best Practices
- Descriptive messages with "feat:", "fix:", "docs:" prefixes
- Large files (checkpoints) never committed
- Multi-line commit messages with context

---

## üîê Production Config Settings

### Generative Augmentation Toggle
```python
# src/utils/production_config.py
USE_GENERATIVE_AUGMENTATION = True  # Master switch
```

### Augmentation Parameters
```python
GENERATIVE_AUG_PROB = 0.3          # 30% of batches use gen aug
GENERATIVE_AUG_MIX_RATIO = (0.2, 0.4)  # Replace 20-40% per batch
GENERATIVE_AUG_INFERENCE_STEPS = 50    # SDXL diffusion steps
GENERATIVE_AUG_BATCH_LIMIT = 8         # Max images per generation
GENERATIVE_AUG_MAX_MODELS = 1          # Only one SDXL model needed
GENERATIVE_AUG_PHASES = ['I', 'P', 'R'] # All phases enabled
```

**Tuning for Performance:**
- Reduce `INFERENCE_STEPS` to 30 for faster generation
- Reduce `BATCH_LIMIT` to 4 if GPU memory limited
- Set `USE_GENERATIVE_AUGMENTATION = False` to disable entirely

---

## üéØ Immediate Next Steps

### Priority 1: Validate Lazy Loading Fix
```bash
source /opt/miniforge3/bin/activate multimodal
python agent_communication/generative_augmentation/test_generative_aug.py --quick --fresh
```

**Expected Outcome:**
- ‚úÖ No thread exhaustion errors
- ‚úÖ Training starts successfully
- ‚úÖ SDXL loads on first generation (if checkpoints present)
- ‚úÖ Test completes with baseline and gen-aug results

### Priority 2: Full Test Run
```bash
python agent_communication/generative_augmentation/test_generative_aug.py --fresh
```

**Purpose:** Compare baseline vs generative augmentation performance on full test

### Priority 3: Production Training
```bash
python src/main.py \
  --modality metadata depth_rgb depth_map thermal_map \
  --device-mode multi \
  --resume_mode fresh
```

**Purpose:** Full multi-modal training with generative augmentation enabled

---

## üìö Documentation Files

### For AI Agents
- **This file:** `AI_AGENT_HANDOFF.md` - Complete project context

### For Users/Developers
- `GENERATIVE_AUGMENTATION_MIGRATION_GUIDE.md` - Technical overview
- `LOCAL_AGENT_MIGRATION_INSTRUCTIONS.md` - Step-by-step setup
- `README.md` - Project readme
- `USAGE_GUIDE.md` - Usage instructions
- `Running_Codes_Examples.sh` - Example commands

### Technical Documentation
- `tracker.md` - Project progress tracker (65K)
- `claude.md` - Claude-specific notes
- `docs/` - Additional documentation

---

## ‚ö†Ô∏è Important Warnings

### DO NOT:
1. ‚ùå Modify files in `agent_communication/generative_augmentation/` (user explicitly requested)
2. ‚ùå Commit large checkpoint files (*.pt, *.pth) to git
3. ‚ùå Use old `generative_augmentation_v2.py` - replaced by SDXL version
4. ‚ùå Run force push to main/master branches
5. ‚ùå Load SDXL in `__init__` - use lazy loading pattern

### DO:
1. ‚úÖ Use lazy loading for expensive models
2. ‚úÖ Check for missing checkpoints gracefully
3. ‚úÖ Limit thread usage when combining PyTorch + TensorFlow
4. ‚úÖ Test changes with `--quick` flag first
5. ‚úÖ Keep experimental code separate from production

---

## üí° Troubleshooting Quick Reference

### Thread Creation Errors
**Symptom:** `pthread_create() failed. Error code 11`
**Solution:** Already fixed with lazy loading + thread limits

### CUDA Out of Memory
**Solution:**
```python
# Reduce in production_config.py
GENERATIVE_AUG_BATCH_LIMIT = 4  # Down from 8
```

### Slow Generation
**Solution:**
```python
# Reduce in production_config.py
GENERATIVE_AUG_INFERENCE_STEPS = 30  # Down from 50
```

### Missing Checkpoints
**Expected:** Checkpoints not in git (too large)
**Verify:**
```bash
ls -lh /workspace/DFUMultiClassification/src/models/sdxl_checkpoints/
```

### Import Errors
**Solution:**
```bash
export PYTHONPATH=/workspace/DFUMultiClassification:$PYTHONPATH
cd /workspace/DFUMultiClassification
```

---

## üé¨ Session Summary

This session focused on migrating the SDXL generative augmentation system from experimental to production. Key achievements:

1. ‚úÖ Successfully migrated all utility files and integration code
2. ‚úÖ Fixed critical thread exhaustion bug with lazy loading
3. ‚úÖ Implemented graceful handling of missing checkpoints
4. ‚úÖ Created comprehensive documentation for handoff
5. ‚úÖ Optimized resource usage (PyTorch thread limits)

**Current Status:**
- Code is production-ready
- Awaiting validation test run by user
- All documentation complete

**Remaining Work:**
- User needs to validate lazy loading fix works
- Full test run to compare baseline vs generative augmentation
- Production training runs

---

## üìû Contact & Resources

### User Information
- **Username:** rezabasiri
- **Repository:** DFUMultiClassification
- **Branch:** claude/run-dataset-polishing-X1NHe

### Key Resources
- **SDXL Model:** stabilityai/stable-diffusion-xl-base-1.0
- **Checkpoints:** Local only (~20GB total, not in git)
- **Training Logs:** `agent_communication/generative_augmentation/reports/`

---

**Handoff Complete.** This document contains all information needed for a new AI agent to continue this project. Good luck! üöÄ
