2026-01-04 22:38:19.539178: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2026-01-04 22:38:19.539220: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2026-01-04 22:38:19.540782: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2026-01-04 22:38:20.397612: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(

================================================================================
DEVICE CONFIGURATION (mode: multi)
================================================================================

Detected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 1: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 2: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 3: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 4: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 5: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 6: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)
  GPU 7: NVIDIA GeForce RTX 4090 - 24.0GB (compute 8.9)

Selected 8 GPU(s):
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 2: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 3: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 4: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 5: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 6: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 7: NVIDIA GeForce RTX 4090 (24.0GB)
Enabled memory growth for 8 GPU(s)

Using MirroredStrategy (8 GPUs) with NCCL
  Compute capability 8.9 detected (native NCCL support)
  (Using NCCL for fastest multi-GPU communication)
  Effective batch size: 8Ã— global batch size
================================================================================


Batch size per replica: 40 (global batch size: 323, replicas: 8)

================================================================================
DFU MULTIMODAL CLASSIFICATION - PRODUCTION PIPELINE
================================================================================
Mode: search
Resume mode: fresh
Data percentage: 30.0%
Verbosity: 2 (DETAILED)
Device: GPUs [0, 1, 2, 3, 4, 5, 6, 7] (multi-GPU mode, MirroredStrategy)
  Replicas: 8Ã— batch size distribution
Train/validation split: 67% train / 33% val

Configuration loaded from: src/utils/production_config.py
Image size: 32x32
Batch size: 323
  Per-GPU batch: 40 (323 / 8 GPUs)
Max epochs: 300 (with early stopping)
Modality search mode: custom
Will test 1 custom combinations
================================================================================


ðŸ§¹ FRESH START MODE: Deleting all checkpoints...
================================================================================

Cleanup Statistics:
  Models: 2 files deleted
  Predictions: 12 files deleted
  Csv Results: 7 files deleted
  Patient Splits: 1 files deleted
  Tf Cache: 4 files deleted
================================================================================


================================================================================
MODALITY SEARCH MODE: CUSTOM (1 combinations)
================================================================================
Testing only specified combinations from production_config.py
Total combinations to test: 1
Cross-validation mode: single split
Iterations per combination: 1
Total training sessions: 1
Results will be saved to: /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv
================================================================================


Testing modalities: thermal_map
Number of samples for each selected modality:
  thermal_map: 3107
  thermal_bb: 3107
Using 30.0% of the data: 932 samples
Using strategy from main: MirroredStrategy

================================================================================
MULTI-GPU TRAINING: 8 GPUs
Global batch size: 323 (per-GPU: 40)
Strategy: MirroredStrategy
================================================================================


Run 1/1
Processing metadata shape...

Unique cases: 427 (before oversampling)

True binary label distributions (unique cases):
Binary1: label_bin1
1    290
0    137
Name: count, dtype: int64
Binary2: label_bin2
0    380
1     47
Name: count, dtype: int64
Original class distribution (ordered):
Class 0: 243
Class 1: 473
Class 2: 86

Calculated alpha values from original distribution:
Alpha values (ordered) [I, P, R]: [0.691, 0.355, 1.953]
Using simple random oversampling...
Original class distribution (ordered):
Class 0: 243
Class 1: 473
Class 2: 86

After oversampling (ordered):
Class 0: 473
Class 1: 473
Class 2: 473

Alpha values after oversampling [I, P, R]: [1.0, 1.0, 1.0]
(Should be close to [1, 1, 1] since data is balanced)
Feature selection: 54 â†’ 40 features
Top 5 features: ['Onset (Days)', 'Wound Centre Temperature Normalized (Â°C)', 'Peri-Ulcer Temperature Normalized (Â°C)', 'BMI', 'Weight (Kg)']
Using Scikit-learn RandomForestClassifier
Using 40 features from training selection
Healing Phase Abs type: <class 'numpy.ndarray'> shape: (1419,)
Healing Phase Abs type: <class 'numpy.ndarray'> shape: (130,)
2026-01-04 22:38:36.507744: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Setting image shapes to 32x32...

Preparing datasets for Run 1/1 with all modalities: ['thermal_map']
Generating new patient split for run 1 (will be reused for all combinations)
Found valid split after 1 attempts

Final class distributions:
Training: {0: 0.314, 1: 0.588, 2: 0.099}
Validation: {0: 0.253, 1: 0.597, 2: 0.15}
Saved patient split for run 1 to /workspace/DFUMultiClassification/results/checkpoints/patient_split_run1.npz
  Train patients: 128, Valid patients: 64
Original class distribution (ordered):
Class 0: 213
Class 1: 399
Class 2: 67

Calculated alpha values from original distribution:
Alpha values (ordered) [I, P, R]: [0.637, 0.34, 2.024]
Using simple random oversampling...
Original class distribution (ordered):
Class 0: 213
Class 1: 399
Class 2: 67

After oversampling (ordered):
Class 0: 399
Class 1: 399
Class 2: 399

Alpha values after oversampling [I, P, R]: [1.0, 1.0, 1.0]
(Should be close to [1, 1, 1] since data is balanced)
thermal_map type: <class 'numpy.ndarray'> shape: (1197,)
Healing Phase Abs type: <class 'numpy.ndarray'> shape: (1197,)
Healing Phase Abs type: <class 'numpy.ndarray'> shape: (253,)
thermal_map type: <class 'numpy.ndarray'> shape: (253,)

No existing data found for thermal_map, starting fresh

Training thermal_map with modalities: ['thermal_map'], run 1/1
