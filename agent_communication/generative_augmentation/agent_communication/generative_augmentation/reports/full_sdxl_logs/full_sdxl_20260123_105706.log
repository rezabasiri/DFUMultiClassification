Logging to: agent_communication/generative_augmentation/reports/full_sdxl_logs/full_sdxl_20260123_105706.log
================================================================================
Training Configuration: configs/full_sdxl.yaml
Phase: all
Modality: rgb
Resolution: 512
================================================================================
Loading base model: stabilityai/stable-diffusion-xl-base-1.0
Detected SDXL model - loading dual text encoders
Enabled gradient checkpointing
Full Fine-tuning:
  Trainable parameters: 2,567,463,684 (100.00%)
/venv/multimodal/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/venv/multimodal/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Enabled perceptual loss
Enabled EMA (on CPU to save GPU memory)
Using phase-specific prompts for conditioning
Loaded 2884 bounding boxes from /workspace/DFUMultiClassification/data/raw/bounding_box_depth.csv
Using 30% of data: 857/2860 images for rgb/all phases
  Phase I: 258/860 images (30.0%)
  Phase P: 503/1678 images (30.0%)
  Phase R: 96/322 images (29.8%)
Using phase-specific prompts for phases: ['I', 'P', 'R']
Stratified split: 770 train, 87 validation
  Phase I: 232 train, 26 val (89.9%/10.1%)
  Phase P: 452 train, 51 val (89.9%/10.1%)
  Phase R: 86 train, 10 val (89.6%/10.4%)
Auto-computed class weights from data:
  Phase counts: {'I': 232, 'P': 452, 'R': 86}
  Weights: {'I': 1.9482758620689655, 'P': 1.0, 'R': 5.255813953488372}
Using balanced sampling with WeightedRandomSampler
Warmup: 0.0% of 77000 steps = 15 steps
Installed CUDA version 12.1 does not match the version torch was compiled with 12.8 but since the APIs are compatible, accepting this combination
Before initializing optimizer states
MA 6.52 GB         Max_MA 7.42 GB         CA 7.44 GB         Max_CA 7 GB 
CPU Virtual Memory:  used = 69.9 GB, percent = 13.9%
After initializing optimizer states
MA 6.52 GB         Max_MA 6.52 GB         CA 7.44 GB         Max_CA 7 GB 
CPU Virtual Memory:  used = 77.05 GB, percent = 15.3%
After initializing ZeRO optimizer
MA 6.52 GB         Max_MA 6.52 GB         CA 7.44 GB         Max_CA 7 GB 
CPU Virtual Memory:  used = 77.14 GB, percent = 15.3%
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
/venv/multimodal/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/venv/multimodal/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Loading model from: /venv/multimodal/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth
/venv/multimodal/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.
  warnings.warn(*args, **kwargs)

Starting training...
Training on 5 GPUs
Total epochs: 200
Effective batch size: 120

Epoch 1/200
  Step 1/77 - Loss: 0.3015, LR: 0.00e+00
  Step 50/77 - Loss: 0.1157, LR: 3.00e-06
  Epoch 1 complete - Loss: 0.1210, LR: 3.00e-06
Train loss: 0.1210
  Validation: 9 batches - Loss: 0.0547
Val loss: 0.0547
Creating fresh reference images from source data with bbox-aware cropping...
Loaded 2884 bounding boxes for reference images
Loaded 16 reference images for phase I
Loaded 16 reference images for phase P
Loaded 16 reference images for phase R
Saved 16 reference images for phase I to agent_communication/generative_augmentation/reports/full_sdxl_logs/reference_images/reference_I.pt
Saved 16 reference images for phase P to agent_communication/generative_augmentation/reports/full_sdxl_logs/reference_images/reference_P.pt
Saved 16 reference images for phase R to agent_communication/generative_augmentation/reports/full_sdxl_logs/reference_images/reference_R.pt
Saved reference image grid to agent_communication/generative_augmentation/reports/full_sdxl_logs/reference_images/reference_images_grid.png
Computing quality metrics...
Generating 50 images across 3 phases...
  Phase I: generating 17 images...
  Phase P: generating 17 images...
  Phase R: generating 16 images...
Computing FID...
Computing SSIM...
Computing LPIPS...
Computing Inception Score...

Per-phase metrics:
==================================================
Phase I: SSIM=0.3193, LPIPS=0.9822
Phase P: SSIM=0.2496, LPIPS=1.0270
Phase R: SSIM=0.2537, LPIPS=1.0685
==================================================
Quality Metrics:
==================================================
FID: 418.26 (lower is better, < 50 is good)
SSIM: 0.2885 ± 0.1173 (higher is better, > 0.7 is good)
LPIPS: 0.9925 ± 0.0426 (lower is better, < 0.3 is good)
IS: 3.37 ± 0.33 (higher is better, > 2.0 is good)
==================================================
Val FID: 418.26
  Saved checkpoint: agent_communication/generative_augmentation/checkpoints/full_sdxl/checkpoint_epoch_0001.pt

Epoch 2/200
  Step 1/77 - Loss: 0.0352, LR: 3.00e-06
  Step 50/77 - Loss: 0.1109, LR: 3.00e-06
