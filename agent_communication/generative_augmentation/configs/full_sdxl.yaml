# SDXL 1.0 Base - 256x256 (Full Fine-tuning)
model:
  base_model: "stabilityai/stable-diffusion-xl-base-1.0"
  resolution: 512  # Ideal resolution for SDXL - testing with DeepSpeed ZeRO-2
  training_method: "full"  # Full fine-tuning for maximum quality (like successful SD 1.5 approach)

lora:
  rank: 128  # MAXIMUM rank for best medical domain adaptation
  alpha: 256  # 2x rank
  dropout: 0.05  # Reduced dropout for maximum capacity
  # CRITICAL: Added feed-forward modules to learn wound-specific textures
  # Attention modules (to_q, to_k, to_v) = spatial relationships
  # Feed-forward modules (ff.net) = visual features/textures
  target_modules: ["to_q", "to_k", "to_v", "to_out.0", "ff.net.0.proj", "ff.net.2"]
  bias: "none"

data:
  data_root: "/workspace/DFUMultiClassification/data/diffusion"  # New organized data
  bbox_file: "/workspace/DFUMultiClassification/data/raw/bounding_box_depth.csv"  # Bbox annotations
  modality: "rgb"
  phase: "all"  # Use all phases (I=860, P=1678, R=322) = 2860 images total
  data_percentage: 100  # Use 100% of images from each phase (balanced sampling)
  train_val_split: 0.90  # 90% train, 10% validation
  split_seed: 42
  augmentation:
    enabled: true
    horizontal_flip: true
    vertical_flip: true
    rotation_degrees: 15
    color_jitter:
      brightness: 0.05  # Reduced - wounds have class-specific colors
      contrast: 0.05    # Reduced - preserve tissue appearance
      saturation: 0.05  # Reduced - wound phases have distinct coloration
      hue: 0.01         # Minimal - critical for phase identification
    bbox_crop_prob: 1.0  # 100% bbox crop - only show wound area, exclude images without bbox
    bbox_margin_range: [0.05, 0.15]  # Add 5-15% random margin around bbox

training:
  batch_size_per_gpu: 4  # Moderate batch size
  gradient_accumulation_steps: 4  # REQUIRED - prevents NaN by slowing LR ramp. Effective batch = 4 * 4 * 5 GPUs = 80
  learning_rate: 5.0e-6  # Lowered from 1e-5 to prevent NaN gradients (still 5x higher than original 1e-6)
  lr_scheduler: "cosine"  # Cosine annealing
  lr_warmup_steps: 100  # Short warmup - reach target LR in ~1 epoch, not 4 epochs
  lr_num_cycles: 1
  optimizer: "adamw"
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_weight_decay: 0.01
  adam_epsilon: 1.0e-8
  max_grad_norm: 1.0
  max_epochs: 300  # High limit, early stopping will end training when converged
  early_stopping:
    enabled: true
    patience: 30  # Stop if no improvement for 30 epochs
    min_delta: 0.01
    monitor: "val_loss"  # Metric to monitor for early stopping
    mode: "min"  # "min" for loss, "max" for accuracy

prompts:
  enabled: true
  # MINIMAL prompts - force model to learn from training data, not pretrained knowledge
  # Detailed prompts cause SDXL to generate from pretrained "clinical photo" knowledge
  # Simple prompts force reliance on learned features from training images
  phase_prompts:
    I: "diabetic foot ulcer, inflammatory phase"
    P: "diabetic foot ulcer, proliferative phase"
    R: "diabetic foot ulcer, remodeling phase"
  # Fallback positive prompt (used if phase_prompts not available)
  positive: "diabetic foot ulcer"
  negative: >
    blurry, out of focus, low quality, jpeg artifacts, noise, grainy,
    cartoon, illustration, drawing, painting, artistic, stylized, anime,
    artificial, fake, CGI, 3D render, digital art, unrealistic,
    smooth plastic skin, mannequin, doll, toy,
    healthy unblemished skin, no wound, perfect skin,
    text, watermark, logo, signature, border, frame,
    feet, toes, body parts, limbs, person, full body, distant view,
    extreme wide shot, background clutter, unrelated objects

quality:
  perceptual_loss:
    enabled: false  # DISABLED - VGG trained on ImageNet pushes toward "natural" style, not medical realism
    weight: 0.01
    vgg_layer: 16
  ema:
    enabled: true
    decay: 0.99  # FAST EMA (was 0.999) - 63% new weights after epoch 1, not 12%
    use_ema_weights_for_inference: false  # DISABLED - use main model to see actual learning, not EMA
  guidance_scale: 3.0  # REDUCED from 12.0 - lower guidance = less prompt reliance, more training data learning
  inference_steps_training: 50
  inference_steps_production: 50

checkpointing:
  output_dir: "agent_communication/generative_augmentation/checkpoints/full_sdxl"
  save_every_n_epochs: 5  # Save checkpoint every 10 epochs
  keep_last_n_checkpoints: 2  # Keep only 2 checkpoints: best + last
  save_best_only: false
  resume_from_checkpoint: null
  save_optimizer_state: true

metrics:
  compute_every_n_epochs: 5  # FID every 10 epochs
  num_samples_for_metrics: 50
  generation_batch_size: 1  # Generate images in batches to avoid OOM at 512x512
  fid:
    enabled: true
    target_threshold: 50.0
  ssim:
    enabled: true
    target_threshold: 0.70
  lpips:
    enabled: true
    target_threshold: 0.30
    network: "alex"
  inception_score:
    enabled: true
    target_threshold: 2.0

logging:
  logging_dir: "agent_communication/generative_augmentation/reports/full_sdxl_logs"
  log_every_n_steps: 50 
  save_samples_every_n_epochs: 5  # Save samples every 5 epochs
  num_samples_to_save: 16
  use_tensorboard: true
  use_wandb: false

hardware:
  multi_gpu: true
  num_gpus: 5
  mixed_precision: "no"  # FP32 - testing if BF16 precision causes NaN at higher LR
  gradient_checkpointing: true
  use_xformers: false  # SDXL attention dim incompatible
  enable_cpu_offload: true  # Offload optimizer states to CPU for additional memory savings
  num_workers: 4  # Reduced from 8 to avoid potential deadlock
  pin_memory: true

reproducibility:
  seed: 42
  deterministic: false

validation:
  # NOTE: val_loss is computed every epoch for early stopping to work properly
  # validate_every_n_epochs is kept for backward compatibility but no longer used
  generate_samples: true  # Enable sample generation
  num_validation_samples: 4
  compare_to_real: true
  num_real_samples_for_comparison: 50
  save_reference_images: true  # Save reference images once at start
  num_reference_images_per_phase: 16  # Randomly sample per phase
  reference_images_seed: 42  # For reproducible sampling
