2026-01-19 10:43:07.863807: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2026-01-19 10:43:07.863904: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2026-01-19 10:43:07.865209: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2026-01-19 10:43:07.870931: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2026-01-19 10:43:08.595968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
================================================================================
Training Configuration: configs/test_sd15.yaml
Phase: I
Modality: rgb
Resolution: 128
================================================================================
Loading base model: runwayml/stable-diffusion-v1-5
`torch_dtype` is deprecated! Use `dtype` instead!
Enabled xFormers memory-efficient attention
Enabled gradient checkpointing
LoRA Configuration:
  Rank: 16
  Alpha: 32
  Trainable parameters: 3,188,736 (0.37%)
/venv/multimodal/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/venv/multimodal/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Enabled perceptual loss
Enabled EMA
Found 50 images for rgb/I
Dataset split: 42 train, 8 validation
Loaded 50 reference images from /workspace/DFUMultiClassification/data/DFU_Updated/rgb/I
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
/venv/multimodal/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Loading model from: /venv/multimodal/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth
/venv/multimodal/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.
  warnings.warn(*args, **kwargs)

Starting training...
Training on 1 GPUs
Total epochs: 3
Effective batch size: 2

Epoch 1/3
Epoch 0:   0%|          | 0/21 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/21 [02:51<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/DFUMultiClassification/agent_communication/generative_augmentation/scripts/train_lora_model.py", line 762, in <module>
    main()
  File "/workspace/DFUMultiClassification/agent_communication/generative_augmentation/scripts/train_lora_model.py", line 651, in main
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/workspace/DFUMultiClassification/agent_communication/generative_augmentation/scripts/train_lora_model.py", line 259, in train_one_epoch
    latents = vae.encode(pixel_values).latent_dist.sample()
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
    return method(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/diffusers/models/autoencoders/autoencoder_kl.py", line 192, in encode
    h = self._encode(x)
        ^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/diffusers/models/autoencoders/autoencoder_kl.py", line 166, in _encode
    enc = self.encoder(x)
          ^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/diffusers/models/autoencoders/vae.py", line 171, in forward
    sample = self.mid_block(sample)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/diffusers/models/unets/unet_2d_blocks.py", line 745, in forward
    hidden_states = attn(hidden_states, temb=temb)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/diffusers/models/attention_processor.py", line 605, in forward
    return self.processor(
           ^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/diffusers/models/attention_processor.py", line 2558, in __call__
    hidden_states = xformers.ops.memory_efficient_attention(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/xformers/ops/fmha/__init__.py", line 311, in memory_efficient_attention
    return _memory_efficient_attention(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/xformers/ops/fmha/__init__.py", line 472, in _memory_efficient_attention
    return _memory_efficient_attention_forward(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/xformers/ops/fmha/__init__.py", line 491, in _memory_efficient_attention_forward
    op = _dispatch_fw(inp, False)
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/xformers/ops/fmha/dispatch.py", line 142, in _dispatch_fw
    return _run_priority_list(
           ^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/xformers/ops/fmha/dispatch.py", line 83, in _run_priority_list
    raise NotImplementedError(msg)
NotImplementedError: No operator found for `memory_efficient_attention_forward` with inputs:
     query       : shape=(2, 256, 1, 512) (torch.float16)
     key         : shape=(2, 256, 1, 512) (torch.float16)
     value       : shape=(2, 256, 1, 512) (torch.float16)
     attn_bias   : <class 'NoneType'>
     p           : 0.0
`fa3F@2.8.3-133-gde1584b` is not supported because:
    max(query.shape[-1], value.shape[-1]) > 256
    device=cpu (supported: {'cuda'})
`fa2F@2.5.7-pt` is not supported because:
    max(query.shape[-1], value.shape[-1]) > 256
    device=cpu (supported: {'cuda'})
`cutlassF-pt` is not supported because:
    device=cpu (supported: {'cuda'})
2026-01-19 10:52:49.223080: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2026-01-19 10:52:49.223168: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2026-01-19 10:52:49.224354: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2026-01-19 10:52:49.230093: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2026-01-19 10:52:49.930817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
================================================================================
Training Configuration: configs/test_sd15.yaml
Phase: I
Modality: rgb
Resolution: 128
================================================================================
Loading base model: runwayml/stable-diffusion-v1-5
`torch_dtype` is deprecated! Use `dtype` instead!
Enabled gradient checkpointing
LoRA Configuration:
  Rank: 16
  Alpha: 32
  Trainable parameters: 3,188,736 (0.37%)
/venv/multimodal/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/venv/multimodal/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Enabled perceptual loss
Enabled EMA
Found 50 images for rgb/I
Dataset split: 42 train, 8 validation
Loaded 50 reference images from /workspace/DFUMultiClassification/data/DFU_Updated/rgb/I
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
/venv/multimodal/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Loading model from: /venv/multimodal/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth
/venv/multimodal/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.
  warnings.warn(*args, **kwargs)

Starting training...
Training on 1 GPUs
Total epochs: 3
Effective batch size: 2

Epoch 1/3
Epoch 0:   0%|          | 0/21 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/21 [03:59<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/DFUMultiClassification/agent_communication/generative_augmentation/scripts/train_lora_model.py", line 793, in <module>
    main()
  File "/workspace/DFUMultiClassification/agent_communication/generative_augmentation/scripts/train_lora_model.py", line 682, in main
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/workspace/DFUMultiClassification/agent_communication/generative_augmentation/scripts/train_lora_model.py", line 319, in train_one_epoch
    diff_loss = compute_diffusion_loss(
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/DFUMultiClassification/agent_communication/generative_augmentation/scripts/train_lora_model.py", line 249, in compute_diffusion_loss
    loss = F.mse_loss(model_pred.float(), target.float(), reduction="mean")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/multimodal/lib/python3.11/site-packages/torch/nn/functional.py", line 3885, in mse_loss
    return torch._C._nn.mse_loss(
           ^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
