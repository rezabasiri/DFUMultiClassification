2026-01-26 08:59:47,502 - DEBUG - [DEBUG] main() started
2026-01-26 08:59:47,502 - DEBUG - [DEBUG] Python version: 3.11.14 | packaged by conda-forge | (main, Oct 22 2025, 22:46:25) [GCC 14.3.0]
2026-01-26 08:59:47,502 - DEBUG - [DEBUG] Project root: /workspace/DFUMultiClassification
2026-01-26 08:59:47,502 - DEBUG - [DEBUG] Log file: /workspace/DFUMultiClassification/agent_communication/generative_augmentation/gengen_test.log
2026-01-26 08:59:47,504 - DEBUG - [DEBUG] Parsed arguments: fresh=False, quick=True
2026-01-26 08:59:47,504 - INFO - ================================================================================
2026-01-26 08:59:47,504 - INFO - QUICK TEST MODE: 30.0% data, 3 epochs, 32x32 images
2026-01-26 08:59:47,504 - INFO - This is for error checking only - results not production-ready
2026-01-26 08:59:47,504 - INFO - ================================================================================

2026-01-26 08:59:47,504 - DEBUG - [DEBUG] Quick mode settings: QUICK_BATCH_SIZE=256, QUICK_STAGE1_EPOCHS=1
2026-01-26 08:59:47,504 - DEBUG - [DEBUG] Quick mode settings: QUICK_EARLY_STOP_PATIENCE=3, QUICK_REDUCE_LR_PATIENCE=1
2026-01-26 08:59:47,504 - DEBUG - [DEBUG] Saving original config...
2026-01-26 08:59:47,505 - INFO - Saved original production_config values
2026-01-26 08:59:47,505 - DEBUG - [DEBUG] Original config saved: ['USE_GENERATIVE_AUGMENTATION', 'INCLUDED_COMBINATIONS', 'DATA_PERCENTAGE', 'N_EPOCHS', 'IMAGE_SIZE', 'STAGE1_EPOCHS', 'EARLY_STOP_PATIENCE', 'REDUCE_LR_PATIENCE', 'LR_SCHEDULE_EXPLORATION_EPOCHS', 'GLOBAL_BATCH_SIZE', 'GENERATIVE_AUG_INFERENCE_STEPS', 'GENERATIVE_AUG_BATCH_LIMIT', 'GENERATIVE_AUG_PROB', 'GENERATIVE_AUG_NUM_GPUS']
2026-01-26 08:59:47,505 - INFO - Resuming test run - 1/2 tests completed
2026-01-26 08:59:47,505 - DEBUG - [DEBUG] Loaded progress: completed=['baseline'], results_keys=['baseline']
2026-01-26 08:59:47,505 - DEBUG - [DEBUG] Starting test loop with 2 configs
2026-01-26 08:59:47,505 - DEBUG - [DEBUG] Processing config 1/2: baseline
2026-01-26 08:59:47,505 - INFO - 
Skipping Baseline (no generative augmentation) (already completed)
2026-01-26 08:59:47,505 - DEBUG - [DEBUG] Skipping baseline - already in completed list
2026-01-26 08:59:47,505 - DEBUG - [DEBUG] Processing config 2/2: gengen_enabled
2026-01-26 08:59:47,505 - INFO - 
================================================================================
2026-01-26 08:59:47,505 - INFO - Starting test 2/2
2026-01-26 08:59:47,505 - INFO - ================================================================================
2026-01-26 08:59:47,505 - DEBUG - [DEBUG] About to call run_test for gengen_enabled
2026-01-26 08:59:47,505 - DEBUG - [DEBUG] Config: {'name': 'gengen_enabled', 'description': 'With generative augmentation (depth_rgb)', 'use_gen_aug': True}
2026-01-26 08:59:47,505 - INFO - 
================================================================================
2026-01-26 08:59:47,505 - INFO - TEST: With generative augmentation (depth_rgb)
2026-01-26 08:59:47,505 - INFO - ================================================================================
2026-01-26 08:59:47,505 - DEBUG - [DEBUG] run_test called: config_name=gengen_enabled, use_gen_aug=True
2026-01-26 08:59:47,505 - DEBUG - [DEBUG] QUICK_MODE=True, DATA_PERCENTAGE=30.0, N_EPOCHS=3, IMAGE_SIZE=32
2026-01-26 08:59:47,505 - INFO - Deleted cached dataset: depth_map_depth_rgb_metadata_thermal_map_15pct.csv
2026-01-26 08:59:47,506 - INFO - Deleted cached outliers: outliers_depth_map_depth_rgb_metadata_thermal_map_15pct.csv
2026-01-26 08:59:47,506 - DEBUG - [DEBUG] update_config_for_test called with use_gen_aug=True
2026-01-26 08:59:47,506 - DEBUG - [DEBUG] Read production_config (20183 bytes)
2026-01-26 08:59:47,507 - DEBUG - [DEBUG] Config updated: USE_GENERATIVE_AUGMENTATION=True, QUICK_MODE=True
2026-01-26 08:59:47,507 - DEBUG - [DEBUG] Quick mode config: DATA_PERCENTAGE=30.0, N_EPOCHS=3, IMAGE_SIZE=32, BATCH_SIZE=256
2026-01-26 08:59:47,507 - DEBUG - [DEBUG] Quick mode SDXL: INFERENCE_STEPS=10, BATCH_LIMIT=4, PROB=0.2, NUM_GPUS=3
2026-01-26 08:59:47,507 - INFO - Config updated: USE_GENERATIVE_AUGMENTATION=True
2026-01-26 08:59:47,507 - INFO - Modalities: metadata, depth_rgb, depth_map, thermal_map
2026-01-26 08:59:47,507 - INFO - Running: /venv/multimodal/bin/python src/main.py --data_percentage 30.0 --resume_mode fresh --device-mode multi
2026-01-26 08:59:47,507 - DEBUG - [DEBUG] Working directory: /workspace/DFUMultiClassification
2026-01-26 08:59:47,507 - DEBUG - [DEBUG] Log start position: 4249
2026-01-26 08:59:47,507 - DEBUG - [DEBUG] Starting subprocess...
2026-01-26 08:59:47,508 - DEBUG - [DEBUG] Subprocess started with PID: 2539
2026-01-26 08:59:53,995 - INFO -   Cross-validation: 3-fold CV (patient-level)
2026-01-26 08:59:53,995 - INFO -   Max epochs: 3 (with early stopping)
2026-01-26 08:59:55,284 - INFO -     Training will use 2729 samples (outliers excluded)
2026-01-26 08:59:55,285 - INFO -   Cross-validation mode: 3-fold CV
2026-01-26 08:59:55,285 - INFO -   Total training sessions: 3
2026-01-26 08:59:55,342 - INFO -   MULTI-GPU TRAINING: 5 GPUs
2026-01-26 08:59:55,343 - INFO -   GENERATING 3-FOLD CROSS-VALIDATION SPLITS (PATIENT-LEVEL)
2026-01-26 08:59:55,384 - INFO -   STRATIFIED K-FOLD SPLIT - CLASS DISTRIBUTION CHECK
2026-01-26 08:59:55,385 - INFO -   Fold 1/3: 114 train patients, 59 valid patients
2026-01-26 08:59:55,386 - INFO -   Fold 2/3: 115 train patients, 58 valid patients
2026-01-26 08:59:55,387 - INFO -   Fold 3/3: 117 train patients, 56 valid patients
2026-01-26 08:59:55,387 - INFO -   Generated 3 folds
2026-01-26 08:59:55,387 - INFO -   All data will be validated exactly once across all folds
2026-01-26 08:59:55,587 - INFO -   Fold 1/3
2026-01-26 08:59:55,587 - INFO -   Using pre-computed fold 1 patient split
2026-01-26 08:59:59,847 - INFO -   Preparing datasets for Fold 1/3 with all modalities: ['thermal_map', 'depth_rgb', 'metadata', 'depth_map']
2026-01-26 09:00:03,955 - INFO -   Training metadata+depth_rgb+depth_map+thermal_map with modalities: ['metadata', 'depth_rgb', 'depth_map', 'thermal_map'], fold 1/3
2026-01-26 09:00:48,190 - INFO -   [STATUS] Still running... 1.0 min elapsed, 165 lines processed
2026-01-26 09:00:48,190 - DEBUG - [DEBUG] Last output line: ================================================================================...
2026-01-26 09:00:48,190 - INFO -   AUTOMATIC PRE-TRAINING: depth_rgb weights not found
2026-01-26 09:00:48,190 - INFO -     Training depth_rgb-only model first (same data split)...
2026-01-26 09:03:32,715 - INFO -   [STATUS] Still running... 3.8 min elapsed, 169 lines processed
2026-01-26 09:03:32,715 - DEBUG - [DEBUG] Last output line: WARNING: All log messages before absl::InitializeLog() is called are written to STDERR...
2026-01-26 09:04:19,817 - INFO -     Pre-training completed! Best val kappa: 0.0000
2026-01-26 09:23:22,151 - INFO -   Restoring model weights from the end of the best epoch: 21.
2026-01-26 09:23:22,151 - INFO -   [STATUS] Still running... 23.6 min elapsed, 174 lines processed
2026-01-26 09:23:22,151 - DEBUG - [DEBUG] Last output line: Restoring model weights from the end of the best epoch: 21....
2026-01-26 09:23:24,964 - INFO -   Epoch 31: early stopping
2026-01-26 09:24:31,290 - INFO -   [STATUS] Still running... 24.7 min elapsed, 176 lines processed
2026-01-26 09:24:31,290 - DEBUG - [DEBUG] Last output line: ...
2026-01-26 09:24:31,294 - INFO -       accuracy                           0.53       308
2026-01-26 09:24:31,294 - INFO -   Cohen's Kappa: 0.2520
2026-01-26 09:24:50,374 - INFO -   Training gating network for run 1...
2026-01-26 09:24:50,383 - INFO -   Initializing gating network training...
2026-01-26 09:24:50,386 - INFO -   Accuracy: 0.5292
2026-01-26 09:24:50,386 - INFO -   Kappa: 0.2520
2026-01-26 09:25:21,863 - INFO -   Fold 2/3
2026-01-26 09:25:21,863 - INFO -   Using pre-computed fold 2 patient split
2026-01-26 09:25:44,218 - INFO -   [STATUS] Still running... 25.9 min elapsed, 203 lines processed
2026-01-26 09:25:44,218 - DEBUG - [DEBUG] Last output line: Initializing GenerativeAugmentationManager with models from src/models/sdxl_checkpoints...
2026-01-26 09:25:44,218 - INFO -   Preparing datasets for Fold 2/3 with all modalities: ['thermal_map', 'depth_rgb', 'metadata', 'depth_map']
2026-01-26 09:25:56,749 - INFO -   Training metadata+depth_rgb+depth_map+thermal_map with modalities: ['metadata', 'depth_rgb', 'depth_map', 'thermal_map'], fold 2/3
2026-01-26 09:26:47,638 - INFO -   [STATUS] Still running... 27.0 min elapsed, 212 lines processed
2026-01-26 09:26:47,638 - DEBUG - [DEBUG] Last output line: ================================================================================...
2026-01-26 09:26:47,638 - INFO -   AUTOMATIC PRE-TRAINING: depth_rgb weights not found
2026-01-26 09:26:47,638 - INFO -     Training depth_rgb-only model first (same data split)...
2026-01-26 09:30:23,810 - INFO -     Pre-training completed! Best val kappa: 0.0000
2026-01-26 09:30:23,810 - INFO -   [STATUS] Still running... 30.6 min elapsed, 216 lines processed
2026-01-26 09:30:23,810 - DEBUG - [DEBUG] Last output line:   Pre-training completed! Best val kappa: 0.0000...
V
Iterations per combination: 3
Total training sessions: 3
Results will be saved to: /workspace/DFUMultiClassification/results/csv/modality_combination_results.csv
================================================================================


Testing modalities: metadata, depth_rgb, depth_map, thermal_map
Loaded 2729 samples from best_matching.csv
  Class distribution: I=759, P=1680, R=290
Number of samples for each selected modality:
  depth_rgb: 2729
  depth_bb: 2729
  depth_map: 2729
  thermal_map: 2729
  thermal_bb: 2729
  metadata: 2729
Using 30.0% of the data: 819 samples

================================================================================
MULTI-GPU TRAINING: 5 GPUs
Global batch size: 256 (per-GPU: 51)
Strategy: MirroredStrategy
================================================================================


================================================================================
GENERATING 3-FOLD CROSS-VALIDATION SPLITS (PATIENT-LEVEL)
================================================================================

================================================================================
STRATIFIED K-FOLD SPLIT - CLASS DISTRIBUTION CHECK
================================================================================
Class 0: 58 patients
Class 1: 95 patients
Class 2: 20 patients
================================================================================

Fold 1/3: 114 train patients, 59 valid patients
  Train dist: {0: 0.266, 1: 0.628, 2: 0.106}
  Valid dist: {0: 0.302, 1: 0.610, 2: 0.088}
Fold 2/3: 115 train patients, 58 valid patients
  Train dist: {0: 0.301, 1: 0.622, 2: 0.078}
  Valid dist: {0: 0.239, 1: 0.621, 2: 0.139}
Fold 3/3: 117 train patients, 56 valid patients
  Train dist: {0: 0.272, 1: 0.616, 2: 0.112}
  Valid dist: {0: 0.299, 1: 0.636, 2: 0.065}
Generated 3 folds
All data will be validated exactly once across all folds
================================================================================


Fold 1/3
Using pre-computed fold 1 patient split
Using Scikit-learn RandomForestClassifier
Initializing GenerativeAugmentationManager with models from src/models/sdxl_checkpoints

Preparing datasets for Fold 1/3 with all modalities: ['thermal_map', 'depth_rgb', 'metadata', 'depth_map']
Using consistent patient split across all modality combinations for run 1
Using Scikit-learn RandomForestClassifier

No existing data found for metadata+depth_rgb+depth_map+thermal_map, starting fresh

Training metadata+depth_rgb+depth_map+thermal_map with modalities: ['metadata', 'depth_rgb', 'depth_map', 'thermal_map'], fold 1/3
================================================================================
AUTOMATIC PRE-TRAINING: depth_rgb weights not found
  Training depth_rgb-only model first (same data split)...
================================================================================
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1769418212.715540    2713 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  Pre-training completed! Best val kappa: 0.0000
================================================================================
No existing pretrained weights found
Restoring model weights from the end of the best epoch: 21.
Epoch 31: early stopping

Run 1 Results for metadata+depth_rgb+depth_map+thermal_map:
              precision    recall  f1-score   support

           I       0.43      0.76      0.55        93
           P       0.75      0.46      0.57       188
           R       0.22      0.22      0.22        27

    accuracy                           0.53       308
   macro avg       0.47      0.48      0.45       308
weighted avg       0.61      0.53      0.53       308

Cohen's Kappa: 0.2520

Training gating network for run 1...

Initializing gating network training...
Skipping gating network: only 1 model(s), need at least 2 to combine

Gating Network Results for Run 1:
Accuracy: 0.5292
F1 Macro: 0.4460
Kappa: 0.2520

Fold 2/3
Using pre-computed fold 2 patient split
Using Scikit-learn RandomForestClassifier
Initializing GenerativeAugmentationManager with models from src/models/sdxl_checkpoints

Preparing datasets for Fold 2/3 with all modalities: ['thermal_map', 'depth_rgb', 'metadata', 'depth_map']
Using consistent patient split across all modality combinations for run 2
Using Scikit-learn RandomForestClassifier

No existing data found for metadata+depth_rgb+depth_map+thermal_map, starting fresh

Training metadata+depth_rgb+depth_map+thermal_map with modalities: ['metadata', 'depth_rgb', 'depth_map', 'thermal_map'], fold 2/3
================================================================================
AUTOMATIC PRE-TRAINING: depth_rgb weights not found
  Training depth_rgb-only model first (same data split)...
================================================================================
  Pre-training completed! Best val kappa: 0.0000
================================================================================
No existing pretrained weights found
